{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本配置\n",
    "\n",
    "首先导入必须的包。对于一个PyTorch项目，我们需要导入一些Python常用的包来帮助我们快速实现功能。常见的包有os、numpy等，此外还需要调用PyTorch自身一些PyTorch的模块方便灵活使用，比如torch、torch.nn、torch.utils.data.Dataset、torch.utils.data.DataLoader、torch.optimizer等等。注意这里**只是建议导入的包导入的方式**，可以采用不同的方案，比如涉及到表格信息的读入很可能用到pandas，对于不同的项目可能还需要导入一些更上层的包如cv2等。如果涉及可视化还会用到matplotlib、seaborn等。涉及到下游分析和指标计算也常用到sklearn。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入包\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "根据前面我们对深度学习任务的梳理，有如下几个超参数可以统一设置，方便后续调试时修改：\n",
    "- batch size\n",
    "- 初始学习率（初始）\n",
    "- 训练次数（max_epochs）\n",
    "- GPU配置\n",
    "'''\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU的设置有两种常见的方式：\n",
    "# 方案一：使用os.environ，这种情况如果使用GPU不需要设置\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然还会有一些其他模块或用户自定义模块会用到的参数，有需要也可以在一开始进行设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读入\n",
    "\n",
    "PyTorch数据读入是通过Dataset+Dataloader的方式完成的，Dataset定义好数据的格式和数据变换形式，Dataloader用iterative的方式不断读入批次数据。\n",
    "\n",
    "我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：\n",
    "\n",
    "- `__init__`: 用于向类中传入外部参数，同时定义样本集\n",
    "- `__getitem__`: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据\n",
    "- `__len__`: 用于返回数据集的样本数\n",
    "\n",
    "下面以cifar10数据集为例给出构建Dataset类的方式：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train_data = datasets.ImageFolder(train_path, transform=data_transform)\n",
    "val_data = datasets.ImageFolder(val_path, transform=data_transform)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用了PyTorch自带的ImageFolder类的用于读取按一定结构存储的图片数据（path对应图片存放的目录，目录下包含若干子目录，每个子目录对应一个类的图片）。\n",
    "\n",
    "其中“data_transform”可以对图像进行一定的变换，如翻转、裁剪等操作，可自己定义。这里我们会在下一章通过实战加以介绍。\n",
    "\n",
    "这里另外给出一个例子，其中图片存放在一个文件夹，另外有一个csv文件给出了图片名称对应的标签。这种情况下需要自己来定义Dataset类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, info_csv, image_list, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            info_csv: path to the csv file containing image indexes\n",
    "                with corresponding labels.\n",
    "            image_list: path to the txt file contains image names to training/validation set\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        label_info = pd.read_csv(info_csv)\n",
    "        image_file = open(image_list).readlines()\n",
    "        self.data_dir = data_dir\n",
    "        self.image_file = image_file\n",
    "        self.label_info = label_info\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_file[index].strip('\\n')\n",
    "        raw_label = self.label_info.loc[self.label_info['Image_index'] == image_name]\n",
    "        label = raw_label.iloc[:,0]\n",
    "        image_name = os.path.join(self.data_dir, image_name)\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好Datadet后，就可以使用DataLoader来按批次读入数据了，实现代码如下：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=4, shuffle=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中:\n",
    "\n",
    "- batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数\n",
    "- num_workers：有多少个进程用于读取数据\n",
    "- shuffle：是否将读入的数据打乱\n",
    "- drop_last：对于样本最后一部分没有达到批次数的样本，不再参与训练\n",
    "\n",
    "这里可以看一下我们的加载的数据。PyTorch中的DataLoader的读取可以使用next和iter来完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(iter(val_loader))\n",
    "print(images.shape)\n",
    "plt.imshow(images[0].transpose(1,2,0))\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "\n",
    "#### 3.4.1  神经网络的构造\n",
    "\n",
    "PyTorch中神经网络构造一般是基于 Module 类的模型来完成的，它让模型构造更加灵活。\n",
    "\n",
    "Module 类是 nn 模块里提供的一个模型构造类，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型。下面继承 Module 类构造多层感知机。这里定义的 MLP 类重载了 Module 类的 init 函数和 forward 函数。它们分别用于创建模型参数和定义前向计算。前向计算也即正向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "  def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例例时还可以指定其他函数\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.hidden = nn.Linear(784, 256)\n",
    "    self.act = nn.ReLU()\n",
    "    self.output = nn.Linear(256,10)\n",
    "    \n",
    "   # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "  def forward(self, x):\n",
    "    o = self.act(self.hidden(x))\n",
    "    return self.output(o)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上的 MLP 类中⽆无须定义反向传播函数。系统将通过⾃动求梯度⽽自动⽣成反向传播所需的 backward 函数。\n",
    "\n",
    "我们可以实例化 MLP 类得到模型变量 net 。下⾯的代码初始化 net 并传入输⼊数据 X 做一次前向计算。其中， net(X) 会调用 MLP 继承⾃自 Module 类的 __call__ 函数，这个函数将调⽤用 MLP 类定义的forward 函数来完成前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1626,  0.0354, -0.0072,  0.1289,  0.0699, -0.0441, -0.1062,  0.0483,\n",
       "         -0.4259,  0.2505],\n",
       "        [-0.1299, -0.1311, -0.0107,  0.2428,  0.1173, -0.0040, -0.0029, -0.0319,\n",
       "         -0.4464,  0.2602]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2,784)\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这里并没有将 Module 类命名为 Layer (层)或者 Model (模型)之类的名字，这是因为该类是一个可供⾃由组建的部件。它的子类既可以是⼀个层(如PyTorch提供的 Linear 类)，⼜可以是一个模型(如这里定义的 MLP 类)，或者是模型的⼀个部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2  神经网络中常见的层\n",
    "\n",
    "深度学习的一个魅力在于神经网络中各式各样的层，例如全连接层、卷积层、池化层与循环层等等。虽然PyTorch提供了⼤量常用的层，但有时候我们依然希望⾃定义层。这里我们会介绍如何使用 Module 来自定义层，从而可以被反复调用。\n",
    "\n",
    "- **不含模型参数的层**\n",
    "\n",
    "我们先介绍如何定义一个不含模型参数的自定义层。下⾯构造的 MyLayer 类通过继承 Module 类自定义了一个**将输入减掉均值后输出**的层，并将层的计算定义在了 forward 函数里。这个层里不含模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试，实例化该层，然后做前向计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **含模型参数的层**\n",
    "\n",
    "我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。\n",
    "\n",
    "Parameter 类其实是 Tensor 的子类，如果一 个 Tensor 是 Parameter ，那么它会⾃动被添加到模型的参数列表里。所以在⾃定义含模型参数的层时，我们应该将参数定义成 Parameter ，除了直接定义成 Parameter 类外，还可以使⽤ ParameterList 和 ParameterDict 分别定义参数的列表和字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n",
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)\n",
    "\n",
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面给出常见的神经网络的一些层，比如卷积层、池化层，以及较为基础的AlexNet，LeNet等。\n",
    "\n",
    "- **二维卷积层**\n",
    "\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不不断迭代卷积核和偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 卷积运算（二维互相关）\n",
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "# 二维卷积层\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积窗口形状为 $p \\times q$ 的卷积层称为 $p \\times q$  卷积层。同样，  $p \\times q$ 卷积或 $p \\times q$ 卷积核说明卷积核的高和宽分别为 $p$ 和 $q$。\n",
    "\n",
    "填充(padding)是指在输⼊入⾼高和宽的两侧填充元素(通常是0元素)。\n",
    "\n",
    "下面的例子里我们创建一个⾼和宽为3的二维卷积层，然后设输⼊高和宽两侧的填充数分别为1。给定一 个高和宽为8的输入，我们发现输出的高和宽也是8。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量量⼤大⼩小和通道数\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 排除不关心的前两维:批量和通道\n",
    "\n",
    "\n",
    "# 注意这里是两侧分别填充1⾏或列，所以在两侧一共填充2⾏或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当卷积核的高和宽不同时，我们也可以通过设置高和宽上不同的填充数使输出和输入具有相同的高和宽。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使⽤用高为5、宽为3的卷积核。在⾼和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下 的顺序，依次在输⼊数组上滑动。我们将每次滑动的行数和列数称为步幅(stride)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "填充可以增加输出的高和宽。这常用来使输出与输入具有相同的高和宽。\n",
    "\n",
    "步幅可以减小输出的高和宽，例如输出的高和宽仅为输⼊入的高和宽的 ( 为大于1的整数)。\n",
    "\n",
    "- **池化层**\n",
    "\n",
    "池化层每次对输入数据的一个固定形状窗口(⼜称池化窗口)中的元素计算输出。不同于卷积层里计算输⼊和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也 分别叫做最大池化或平均池化。在二维最⼤池化中，池化窗⼝口从输⼊入数组的最左上⽅方开始，按从左往右、从上往下的顺序，依次在输⼊数组上滑动。当池化窗口滑动到某⼀位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。\n",
    "\n",
    "下面把池化层的前向计算实现在`pool2d`函数里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5.],\n",
       "       [7., 8.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = np.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].float().mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用`torch.nn`包来构建神经网络。我们已经介绍了`autograd`包，`nn`包则依赖于`autograd`包来定义模型并对它们求导。一个`nn.Module`包含各个层和一个`forward(input)`方法，该方法返回`output`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3  模型示例\n",
    "\n",
    "- **LeNet**\n",
    "![3.4.1](./figures/3.4.1.png)\n",
    "\n",
    "这是一个简单的前馈神经网络 (feed-forward network）（LeNet）。它接受一个输入，然后将它送入下一层，一层接一层的传递，最后给出输出。\n",
    "\n",
    "一个神经网络的典型训练过程如下：\n",
    "\n",
    "1. 定义包含一些可学习参数(或者叫权重）的神经网络\n",
    "2. 在输入数据集上迭代\n",
    "3. 通过网络处理输入\n",
    "4. 计算 loss (输出和正确答案的距离）\n",
    "5. 将梯度反向传播给网络的参数\n",
    "6. 更新网络的权重，一般使用一个简单的规则：`weight = weight - learning_rate * gradient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们只需要定义 `forward` 函数，`backward`函数会在使用`autograd`时自动定义，`backward`函数用来计算导数。我们可以在 `forward` 函数中使用任何针对张量的操作和计算。\n",
    "\n",
    "一个模型的可学习参数可以通过`net.parameters()`返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们尝试一个随机的 32x32 的输入。注意:这个网络 (LeNet）的期待输入是 32x32 的张量。如果使用 MNIST 数据集来训练这个网络，要把图片大小重新调整到 32x32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0682,  0.0772, -0.0188, -0.0306,  0.1010, -0.0488, -0.0829, -0.1138,\n",
      "          0.0266, -0.0160]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清零所有参数的梯度缓存，然后进行随机梯度的反向传播："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：`torch.nn`只支持小批量处理 (mini-batches）。整个 `torch.nn` 包只支持小批量样本的输入，不支持单个样本的输入。比如，`nn.Conv2d` 接受一个4维的张量，即`nSamples x nChannels x Height x Width `如果是一个单独的样本，只需要使用`input.unsqueeze(0)` 来添加一个“假的”批大小维度。\n",
    "\n",
    "- `torch.Tensor` - 一个多维数组，支持诸如`backward()`等的自动求导操作，同时也保存了张量的梯度。\n",
    "\n",
    "- `nn.Module `- 神经网络模块。是一种方便封装参数的方式，具有将参数移动到GPU、导出、加载等功能。\n",
    "\n",
    "- `nn.Parameter `- 张量的一种，当它作为一个属性分配给一个`Module`时，它会被自动注册为一个参数。\n",
    "\n",
    "- `autograd.Function` - 实现了自动求导前向和反向传播的定义，每个`Tensor`至少创建一个`Function`节点，该节点连接到创建`Tensor`的函数并对其历史进行编码。\n",
    "\n",
    "下面再介绍一个比较基础的案例AlexNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AlexNet**\n",
    "\n",
    "![3.4.2](./figures/3.4.2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "在深度学习广为盛行的今天，我们可以在脑海里清晰的知道，一个模型要可以达到很好的效果需要学习，也就是我们常说的训练。一个好的训练离不开优质的负反馈，这里的损失函数就是模型的负反馈。\n",
    "\n",
    "![](./figures/3.5.1lossfunciton.png)\n",
    "\n",
    "所以在PyTorch中，损失函数是必不可少的。它是数据输入到模型当中，产生的结果与真实标签的评价指标，我们的模型可以按照损失函数的目标来做出改进。\n",
    "\n",
    "下面我们将开始探索pytorch的所拥有的损失函数。这里将列出PyTorch中常用的损失函数（一般通过torch.nn调用），并详细介绍每个损失函数的功能介绍、数学公式和调用代码。当然，PyTorch的损失函数还远不止这些，在解决实际问题的过程中需要进一步探索、借鉴现有工作，或者设计自己的损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1  二分类交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能**：计算二分类任务时的交叉熵（Cross Entropy）函数。在二分类中，label是{0,1}。对于进入交叉熵函数的input为概率分布的形式。一般来说，input为sigmoid激活层的输出，或者softmax的输出。\n",
    "\n",
    "**主要参数**：\n",
    "`weight`:每个类别的loss设置权值\n",
    "\n",
    "`size_average`:数据为bool，为True时，返回的loss为平均值；为False时，返回的各样本的loss之和。\n",
    "\n",
    "`reduce`:数据类型为bool，为True时，loss的返回是标量。\n",
    "\n",
    "计算公式如下：\n",
    "$$\n",
    "\\ell(x, y)=\\left\\{\\begin{array}{ll}\n",
    "\\operatorname{mean}(L), & \\text { if reduction }=\\text { 'mean' } \\\\\n",
    "\\operatorname{sum}(L), & \\text { if reduction }=\\text { 'sum' }\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss损失函数的计算结果为 tensor(0.8558, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('BCELoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2  交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能**：计算交叉熵函数\n",
    "\n",
    "**主要参数**：\n",
    "`weight`:每个类别的loss设置权值。\n",
    "\n",
    "`size_average`:数据为bool，为True时，返回的loss为平均值；为False时，返回的各样本的loss之和。\n",
    "\n",
    "`ignore_index`:忽略某个类的损失函数。\n",
    "\n",
    "`reduce`:数据类型为bool，为True时，loss的返回是标量。\n",
    "\n",
    "计算公式如下：\n",
    "$$\n",
    "\\operatorname{loss}(x, \\text { class })=-\\log \\left(\\frac{\\exp (x[\\text { class }])}{\\sum_{j} \\exp (x[j])}\\right)=-x[\\text { class }]+\\log \\left(\\sum_{j} \\exp (x[j])\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4255, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3  L1损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1Loss()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 计算输出`y`和真实标签`target`之间的差值的绝对值。\n",
    "\n",
    "我们需要知道的是，`reduction`参数决定了计算模式。有三种计算模式可选：none：逐个元素计算。\n",
    "sum：所有元素求和，返回标量。\n",
    "mean：加权平均，返回标量。 \n",
    "如果选择`none`，那么返回的结果是和输入元素相同尺寸的。默认计算方式是求平均。\n",
    "\n",
    "**计算公式如下：**\n",
    "$$\n",
    "L_{n} = | x_{n}-y_{n}|g)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1损失函数的计算结果为 tensor(0.7951, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('L1损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4  MSE损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*功能：**计算输出`y`和真实标签`target`之差的平方。\n",
    "\n",
    "和`L1Loss`一样，`MSELoss`损失函数中，`reduction`参数决定了计算模式。有三种计算模式可选：none：逐个元素计算。\n",
    "sum：所有元素求和，返回标量。默认计算方式是求平均。\n",
    "\n",
    "**计算公式如下：**\n",
    "\n",
    "$$\n",
    "l_{n}=\\left(x_{n}-y_{n}\\right)^{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE损失函数的计算结果为 tensor(2.0590, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('MSE损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.5  平滑L1 (Smooth L1)损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmoothL1Loss()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** L1的平滑输出，其功能是减轻离群点带来的影响\n",
    "\n",
    "`reduction`参数决定了计算模式。有三种计算模式可选：none：逐个元素计算。\n",
    "sum：所有元素求和，返回标量。默认计算方式是求平均。\n",
    "\n",
    "**提醒：** 之后的损失函数中，关于`reduction` 这个参数依旧会存在。所以，之后就不再单独说明。\n",
    "\n",
    "**计算公式如下：**\n",
    "$$\n",
    "\\operatorname{loss}(x, y)=\\frac{1}{n} \\sum_{i=1}^{n} z_{i}\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "z_{i}=\\left\\{\\begin{array}{ll}\n",
    "0.5\\left(x_{i}-y_{i}\\right)^{2}, & \\text { if }\\left|x_{i}-y_{i}\\right|<1 \\\\\n",
    "\\left|x_{i}-y_{i}\\right|-0.5, & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.SmoothL1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmoothL1Loss损失函数的计算结果为 tensor(0.8822, grad_fn=<SmoothL1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('SmoothL1Loss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**平滑L1与L1的对比**\n",
    "\n",
    "这里我们通过可视化两种损失函数曲线来对比平滑L1和L1两种损失函数的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.Tensor.ndim = property(lambda self: len(self.shape))\n",
    "inputs = torch.linspace(-10, 10, steps=5000)\n",
    "target = torch.zeros_like(inputs)\n",
    "\n",
    "loss_f_smooth = nn.SmoothL1Loss(reduction='none')\n",
    "loss_smooth = loss_f_smooth(inputs, target)\n",
    "loss_f_l1 = nn.L1Loss(reduction='none')\n",
    "loss_l1 = loss_f_l1(inputs,target)\n",
    "\n",
    "plt.plot(inputs.numpy(), loss_smooth.numpy(), label='Smooth L1 Loss')\n",
    "plt.plot(inputs.numpy(), loss_l1, label='L1 loss')\n",
    "plt.xlabel('x_i - y_i')\n",
    "plt.ylabel('loss value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看得出来，对于`smoothL1`来说，在0这个尖端处，过度更为平滑。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.6  目标泊松分布的负对数似然损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoissonNLLLoss()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 泊松分布的负对数似然损失函数\n",
    "\n",
    "**主要参数：**\n",
    "\n",
    "`log_input`：输入是否为对数形式，决定计算公式。\n",
    "\n",
    "`full`：计算所有 loss，默认为 False。\n",
    "\n",
    "`eps`：修正项，避免 input 0 为  时，log(input) 为 nan 的情况。\n",
    "\n",
    "**数学公式：**\n",
    "\n",
    "- 当参数`log_input=True`：\n",
    "$$\n",
    "    \\operatorname{loss}\\left(x_{n}, y_{n}\\right)=e^{x_{n}}-x_{n} \\cdot y_{n}\n",
    "$$\n",
    "\n",
    "\n",
    "- 当参数`log_input=False`：\n",
    "\n",
    "    $$\n",
    "    \\operatorname{loss}\\left(x_{n}, y_{n}\\right)=x_{n}-y_{n} \\cdot \\log \\left(x_{n}+\\text { eps }\\right)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonNLLLoss损失函数的计算结果为 tensor(1.2638, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.PoissonNLLLoss()\n",
    "log_input = torch.randn(5, 2, requires_grad=True)\n",
    "target = torch.randn(5, 2)\n",
    "output = loss(log_input, target)\n",
    "output.backward()\n",
    "\n",
    "print('PoissonNLLLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.7  KL散度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KLDivLoss()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 计算KL散度，也就是计算相对熵。用于连续分布的距离度量，并且对离散采用的连续输出空间分布进行回归通常很有用。\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "`reduction`：计算模式，可为 `none`/`sum`/`mean`/`batchmean`。\n",
    "\n",
    "    none：逐个元素计算。\n",
    "    \n",
    "    sum：所有元素求和，返回标量。\n",
    "    \n",
    "    mean：加权平均，返回标量。\n",
    "    \n",
    "    batchmean：batchsize 维度求平均值。\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{\\mathrm{KL}}(P, Q)=\\mathrm{E}_{X \\sim P}\\left[\\log \\frac{P(X)}{Q(X)}\\right] &=\\mathrm{E}_{X \\sim P}[\\log P(X)-\\log Q(X)] \\\\\n",
    "&=\\sum_{i=1}^{n} P\\left(x_{i}\\right)\\left(\\log P\\left(x_{i}\\right)-\\log Q\\left(x_{i}\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonNLLLoss损失函数的计算结果为 tensor(-0.3335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.5, 0.3, 0.2], [0.2, 0.3, 0.5]])\n",
    "target = torch.tensor([[0.9, 0.05, 0.05], [0.1, 0.7, 0.2]], dtype=torch.float)\n",
    "loss = nn.KLDivLoss()\n",
    "output = loss(inputs,target)\n",
    "\n",
    "print('PoissonNLLLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.8  MarginRankingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarginRankingLoss()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 计算两个向量之间的相似度，用于排序任务。该方法计算两组数据之间的差异。\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "`margin`：边界值，$$x_{1}$$ 与$$x_{2}$$ 之间的差异值。\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "\\operatorname{loss}(x 1, x 2, y)=\\max (0,-y *(x 1-x 2)+\\operatorname{margin})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarginRankingLoss损失函数的计算结果为 tensor(0., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MarginRankingLoss()\n",
    "input1 = torch.randn(3, requires_grad=True)\n",
    "input2 = torch.randn(3, requires_grad=True)\n",
    "target = torch.randn(3).sign()\n",
    "output = loss(input1, input2, target)\n",
    "output.backward()\n",
    "\n",
    "print('MarginRankingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.9  多标签边界损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelMarginLoss()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 对于多标签分类问题计算损失函数。\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "**计算公式：**\n",
    "$$\n",
    "\\operatorname{loss}(x, y)=\\sum_{i j} \\frac{\\max (0,1-x[y[j]]-x[i])}{x \\cdot \\operatorname{size}(0)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text { 其中, } i=0, \\ldots, x \\cdot \\operatorname{size}(0), j=0, \\ldots, y \\cdot \\operatorname{size}(0), \\text { 对于所有的 } i \\text { 和 } j \\text {, 都有 } y[j] \\geq 0 \\text { 并且 }\\\\\n",
    "i \\neq y[j]\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarginRankingLoss损失函数的计算结果为 tensor(0.4500)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MultiLabelMarginLoss()\n",
    "x = torch.FloatTensor([[0.9, 0.2, 0.4, 0.8]])\n",
    "# for target y, only consider labels 3 and 0, not after label -1\n",
    "y = torch.LongTensor([[3, 0, -1, 1]])# 真实的分类是，第3类和第0类\n",
    "output = loss(x, y)\n",
    "\n",
    "print('MarginRankingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.10  二分类损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftMarginLoss()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 二分类的 logistic 损失。\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "\\operatorname{loss}(x, y)=\\sum_{i} \\frac{\\log (1+\\exp (-y[i] \\cdot x[i]))}{x \\cdot \\operatorname{nelement}()}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\text { 其中, } x . \\text { nelement() 为输入 } x \\text { 中的样本个数。注意这里 } y \\text { 也有 } 1 \\text { 和 }-1 \\text { 两种模式。 }\n",
    "\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftMarginLoss损失函数的计算结果为 tensor(0.6764)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.3, 0.7], [0.5, 0.5]])  # 两个样本，两个神经元\n",
    "target = torch.tensor([[-1, 1], [1, -1]], dtype=torch.float)  # 该 loss 为逐个神经元计算，需要为每个神经元单独设置标签\n",
    "\n",
    "loss_f = nn.SoftMarginLoss()\n",
    "output = loss_f(inputs, target)\n",
    "\n",
    "print('SoftMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.11  多分类的折页损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiMarginLoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MultiMarginLoss(p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 计算多分类的折页损失\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "`p：`可选 1 或 2。\n",
    "\n",
    "`weight`：各类别的 loss 设置权值。\n",
    "\n",
    "`margin`：边界值\n",
    "\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "\\operatorname{loss}(x, y)=\\frac{\\sum_{i} \\max (0, \\operatorname{margin}-x[y]+x[i])^{p}}{x \\cdot \\operatorname{size}(0)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text { 其中, } x \\in\\{0, \\ldots, x \\cdot \\operatorname{size}(0)-1\\}, y \\in\\{0, \\ldots, y \\cdot \\operatorname{size}(0)-1\\} \\text {, 并且对于所有的 } i \\text { 和 } j \\text {, }\\\\\n",
    "\\text { 都有 } 0 \\leq y[j] \\leq x \\cdot \\operatorname{size}(0)-1, \\text { 以及 } i \\neq y[j] \\text { 。 }\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiMarginLoss损失函数的计算结果为 tensor(0.6000)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.3, 0.7], [0.5, 0.5]]) \n",
    "target = torch.tensor([0, 1], dtype=torch.long) \n",
    "\n",
    "loss_f = nn.MultiMarginLoss()\n",
    "output = loss_f(inputs, target)\n",
    "\n",
    "print('MultiMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.12  三元组损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripletMarginLoss()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 计算三元组损失。\n",
    "\n",
    "**三元组:** 这是一种数据的存储或者使用格式。<实体1，关系，实体2>。在项目中，也可以表示为< `anchor`, `positive examples` , `negative examples`>\n",
    "\n",
    "在这个损失函数中，我们希望去`anchor`的距离更接近`positive examples`，而远离`negative examples `\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "`p：`可选 1 或 2。\n",
    "\n",
    "\n",
    "`margin`：边界值\n",
    "\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "L(a, p, n)=\\max \\left\\{d\\left(a_{i}, p_{i}\\right)-d\\left(a_{i}, n_{i}\\right)+\\operatorname{margin}, 0\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text { 其中, } d\\left(x_{i}, y_{i}\\right)=\\left\\|\\mathbf{x}_{i}-\\mathbf{y}_{i}\\right\\|_{\\text {・ }}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripletMarginLoss损失函数的计算结果为 tensor(1.0442, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "anchor = torch.randn(100, 128, requires_grad=True)\n",
    "positive = torch.randn(100, 128, requires_grad=True)\n",
    "negative = torch.randn(100, 128, requires_grad=True)\n",
    "output = triplet_loss(anchor, positive, negative)\n",
    "output.backward()\n",
    "print('TripletMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.13  HingEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HingeEmbeddingLoss()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 对输出的embedding结果做Hing损失计算\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "\n",
    "\n",
    "`margin`：边界值\n",
    "\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "l_{n}=\\left\\{\\begin{array}{ll}\n",
    "x_{n}, & \\text { if } y_{n}=1 \\\\\n",
    "\\max \\left\\{0, \\Delta-x_{n}\\right\\}, & \\text { if } y_{n}=-1\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "**注意事项：** 输入x应为两个输入之差的绝对值。\n",
    "\n",
    "可以这样理解，让个输出的是正例yn=1,那么loss就是x，如果输出的是负例y=-1，那么输出的loss就是要做一个比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HingEmbeddingLoss损失函数的计算结果为 tensor(0.7667)\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.HingeEmbeddingLoss()\n",
    "inputs = torch.tensor([[1., 0.8, 0.5]])\n",
    "target = torch.tensor([[1, 1, -1]])\n",
    "output = loss_f(inputs,target)\n",
    "\n",
    "print('HingEmbeddingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.14  余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosineEmbeddingLoss()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 对与两个向量做余弦相似度\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "\n",
    "\n",
    "`margin`：可取值[-1,1] ，推荐为[0,0.5] 。\n",
    "\n",
    "\n",
    "**计算公式：**\n",
    "\n",
    "$$\n",
    "\\operatorname{loss}(x, y)=\\left\\{\\begin{array}{ll}\n",
    "1-\\cos \\left(x_{1}, x_{2}\\right), & \\text { if } y=1 \\\\\n",
    "\\max \\left\\{0, \\cos \\left(x_{1}, x_{2}\\right)-\\text { margin }\\right\\}, & \\text { if } y=-1\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "其中,\n",
    "$$\n",
    "\\cos (\\theta)=\\frac{A \\cdot B}{\\|A\\|\\|B\\|}=\\frac{\\sum_{i=1}^{n} A_{i} \\times B_{i}}{\\sqrt{\\sum_{i=1}^{n}\\left(A_{i}\\right)^{2}} \\times \\sqrt{\\sum_{i=1}^{n}\\left(B_{i}\\right)^{2}}}\n",
    "$$\n",
    "\n",
    "\n",
    "这个损失函数应该是最广为人知道的。对于两个向量，做余弦相似度。将余弦相似度作为一个距离的计算方式，如果两个向量的距离近，则损失函数值小，反之亦然。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineEmbeddingLoss损失函数的计算结果为 tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "loss_f = nn.CosineEmbeddingLoss()\n",
    "inputs_1 = torch.tensor([[0.3, 0.5, 0.7], [0.3, 0.5, 0.7]])\n",
    "inputs_2 = torch.tensor([[0.1, 0.3, 0.5], [0.1, 0.3, 0.5]])\n",
    "target = torch.tensor([[1, -1]], dtype=torch.float)\n",
    "output = loss_f(inputs_1,inputs_2,target)\n",
    "\n",
    "print('CosineEmbeddingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.15  CTC损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTCLoss()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CTCLoss(blank=0, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**功能：** 用于解决时序类数据的分类\n",
    "\n",
    "计算连续时间序列和目标序列之间的损失。CTCLoss对输入和目标的可能排列的概率进行求和，产生一个损失值，这个损失值对每个输入节点来说是可分的。输入与目标的对齐方式被假定为 \"多对一\"，这就限制了目标序列的长度，使其必须是≤输入长度。\n",
    "\n",
    "**主要参数:** \n",
    "\n",
    "\n",
    "`reduction`：计算模式，可为 none/sum/mean。\n",
    "\n",
    "\n",
    "`blank`：blank label。\n",
    "\n",
    "\n",
    "`zero_infinity`：无穷大的值或梯度值为 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTCLoss损失函数的计算结果为 tensor(5.5996, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Target are to be padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "S_min = 10  # Minimum target length, for demonstration purposes\n",
    "\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "# Target are to be un-padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
    "target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "\n",
    "print('CTCLoss损失函数的计算结果为',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch优化器\n",
    "\n",
    "#### 3.6.1  什么是优化器\n",
    "\n",
    "深度学习的目标是通过不断改变网络参数，使得参数能够对输入做各种非线性变换拟合输出，本质上就是一个函数去寻找最优解，只不过这个最优解使一个矩阵，而如何快速求得这个最优解是深度学习研究的一个重点，以经典的resnet-50为例，它大约有2000万个系数需要进行计算，那么我们如何计算出来这么多的系数，有以下两种方法：\n",
    "\n",
    "1. 第一种是最直接的暴力穷举一遍参数，这种方法的实施可能性基本为0，堪比愚公移山plus的难度。\n",
    "2. 为了使求解参数过程更加快，人们提出了第二种办法，即就是是BP+优化器逼近求解。\n",
    "\n",
    "因此，优化器就是根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值，使得模型输出更加接近真实标签。。\n",
    "\n",
    "#### 3.6.2  Pytorch提供的优化器\n",
    "\n",
    "Pytorch很人性化的给我们提供了一个优化器的库torch.optim，在这里面给我们提供了十种优化器。\n",
    "\n",
    "+ torch.optim.ASGD\n",
    "+ torch.optim.Adadelta\n",
    "+ torch.optim.Adagrad\n",
    "+ torch.optim.Adam\n",
    "+ torch.optim.AdamW\n",
    "+ torch.optim.Adamax\n",
    "+ torch.optim.LBFGS\n",
    "+ torch.optim.RMSprop\n",
    "+ torch.optim.Rprop\n",
    "+ torch.optim.SGD\n",
    "+ torch.optim.SparseAdam\n",
    "\n",
    "而以上这些优化算法均继承于`Optimizer`，下面我们先来看下所有优化器的基类`Optimizer`。定义如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self, params, defaults):        \n",
    "        self.defaults = defaults\n",
    "        self.state = defaultdict(dict)\n",
    "        self.param_groups = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Optimizer`有三个属性：**\n",
    "\n",
    "+ `defaults`：存储的是优化器的超参数，例子如下：\n",
    "\n",
    "```python\n",
    "{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}\n",
    "```\n",
    "\n",
    "+ `state`：参数的缓存，例子如下\n",
    "\n",
    "```python\n",
    "defaultdict(<class 'dict'>, {tensor([[ 0.3864, -0.0131],\n",
    "        [-0.1911, -0.4511]], requires_grad=True): {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
    "        [0.0052, 0.0052]])}})\n",
    "```\n",
    "\n",
    "+ `param_groups`：管理的参数组，是一个list，其中每个元素是一个字典，顺序是params，lr，momentum，dampening，weight_decay，nesterov，例子如下\n",
    "\n",
    "```python\n",
    "[{'params': [tensor([[-0.1022, -1.6890],[-1.5116, -1.7846]], requires_grad=True)], 'lr': 1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
    "```\n",
    "\n",
    "**`Optimizer`还有以下的方法：**\n",
    "\n",
    "+ `zero_grad()`：清空所管理参数的梯度，Pytorch的特性是张量的梯度不自动清零，因此每次反向传播后都需要清空梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_grad(self, set_to_none: bool = False):\n",
    "    for group in self.param_groups:\n",
    "        for p in group['params']:\n",
    "            if p.grad is not None:  #梯度不为空\n",
    "                if set_to_none: \n",
    "                    p.grad = None\n",
    "                else:\n",
    "                    if p.grad.grad_fn is not None:\n",
    "                        p.grad.detach_()\n",
    "                    else:\n",
    "                        p.grad.requires_grad_(False)\n",
    "                    p.grad.zero_()# 梯度设置为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `step()`：执行一步梯度更新，参数更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, closure): \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `add_param_group()`：添加参数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_param_group(self, param_group):\n",
    "    assert isinstance(param_group, dict), \"param group must be a dict\"\n",
    "# 检查类型是否为tensor\n",
    "    params = param_group['params']\n",
    "    if isinstance(params, torch.Tensor):\n",
    "        param_group['params'] = [params]\n",
    "    elif isinstance(params, set):\n",
    "        raise TypeError('optimizer parameters need to be organized in ordered collections, but '\n",
    "                        'the ordering of tensors in sets will change between runs. Please use a list instead.')\n",
    "    else:\n",
    "        param_group['params'] = list(params)\n",
    "    for param in param_group['params']:\n",
    "        if not isinstance(param, torch.Tensor):\n",
    "            raise TypeError(\"optimizer can only optimize Tensors, \"\n",
    "                            \"but one of the params is \" + torch.typename(param))\n",
    "        if not param.is_leaf:\n",
    "            raise ValueError(\"can't optimize a non-leaf Tensor\")\n",
    "\n",
    "    for name, default in self.defaults.items():\n",
    "        if default is required and name not in param_group:\n",
    "            raise ValueError(\"parameter group didn't specify a value of required optimization parameter \" +\n",
    "                             name)\n",
    "        else:\n",
    "            param_group.setdefault(name, default)\n",
    "\n",
    "    params = param_group['params']\n",
    "    if len(params) != len(set(params)):\n",
    "        warnings.warn(\"optimizer contains a parameter group with duplicate parameters; \"\n",
    "                      \"in future, this will cause an error; \"\n",
    "                      \"see github.com/pytorch/pytorch/issues/40967 for more information\", stacklevel=3)\n",
    "# 上面好像都在进行一些类的检测，报Warning和Error\n",
    "    param_set = set()\n",
    "    for group in self.param_groups:\n",
    "        param_set.update(set(group['params']))\n",
    "\n",
    "    if not param_set.isdisjoint(set(param_group['params'])):\n",
    "        raise ValueError(\"some parameters appear in more than one parameter group\")\n",
    "# 添加参数\n",
    "    self.param_groups.append(param_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `load_state_dict()` ：加载状态参数字典，可以用来进行模型的断点续训练，继续上次的参数进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(self, state_dict):\n",
    "    r\"\"\"Loads the optimizer state.\n",
    "\n",
    "    Arguments:\n",
    "        state_dict (dict): optimizer state. Should be an object returned\n",
    "            from a call to :meth:`state_dict`.\n",
    "    \"\"\"\n",
    "    # deepcopy, to be consistent with module API\n",
    "    state_dict = deepcopy(state_dict)\n",
    "    # Validate the state_dict\n",
    "    groups = self.param_groups\n",
    "    saved_groups = state_dict['param_groups']\n",
    "\n",
    "    if len(groups) != len(saved_groups):\n",
    "        raise ValueError(\"loaded state dict has a different number of \"\n",
    "                         \"parameter groups\")\n",
    "    param_lens = (len(g['params']) for g in groups)\n",
    "    saved_lens = (len(g['params']) for g in saved_groups)\n",
    "    if any(p_len != s_len for p_len, s_len in zip(param_lens, saved_lens)):\n",
    "        raise ValueError(\"loaded state dict contains a parameter group \"\n",
    "                         \"that doesn't match the size of optimizer's group\")\n",
    "\n",
    "    # Update the state\n",
    "    id_map = {old_id: p for old_id, p in\n",
    "              zip(chain.from_iterable((g['params'] for g in saved_groups)),\n",
    "                  chain.from_iterable((g['params'] for g in groups)))}\n",
    "\n",
    "def cast(param, value):\n",
    "    r\"\"\"Make a deep copy of value, casting all tensors to device of param.\"\"\"\n",
    "    # Copy state assigned to params (and cast tensors to appropriate types).\n",
    "    # State that is not assigned to params is copied as is (needed for\n",
    "    # backward compatibility).\n",
    "    state = defaultdict(dict)\n",
    "    for k, v in state_dict['state'].items():\n",
    "        if k in id_map:\n",
    "            param = id_map[k]\n",
    "            state[param] = cast(param, v)\n",
    "        else:\n",
    "            state[k] = v\n",
    "\n",
    "        # Update parameter groups, setting their 'params' value\n",
    "def update_group(group, new_group):\n",
    "    param_groups = [\n",
    "        update_group(g, ng) for g, ng in zip(groups, saved_groups)]\n",
    "    self.__setstate__({'state': state, 'param_groups': param_groups})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `state_dict()`：获取优化器当前状态信息字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_dict(self):\n",
    "    r\"\"\"Returns the state of the optimizer as a :class:`dict`.\n",
    "\n",
    "    It contains two entries:\n",
    "\n",
    "    * state - a dict holding current optimization state. Its content\n",
    "        differs between optimizer classes.\n",
    "    * param_groups - a dict containing all parameter groups\n",
    "    \"\"\"\n",
    "    # Save order indices instead of Tensors\n",
    "    param_mappings = {}\n",
    "    start_index = 0\n",
    "\n",
    "def pack_group(group):\n",
    "    param_groups = [pack_group(g) for g in self.param_groups]\n",
    "    # Remap state to use order indices as keys\n",
    "    packed_state = {(param_mappings[id(k)] if isinstance(k, torch.Tensor) else k): v\n",
    "                    for k, v in self.state.items()}\n",
    "    return {\n",
    "        'state': packed_state,\n",
    "        'param_groups': param_groups,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.3  实际操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight before step:\n",
      "tensor([[0.2986, 0.7610],\n",
      "        [0.8377, 0.2302]])\n",
      "The grad of weight before step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "The data of weight after step:\n",
      "tensor([[0.1986, 0.6610],\n",
      "        [0.7377, 0.1302]])\n",
      "The grad of weight after step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "The grad of weight after optimizer.zero_grad():\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "optimizer.params_group is \n",
      "[{'params': [tensor([[0.1986, 0.6610],\n",
      "        [0.7377, 0.1302]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
      "weight in optimizer:140658301398544\n",
      "weight in weight:140658301398544\n",
      "\n",
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[0.1986, 0.6610],\n",
      "        [0.7377, 0.1302]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}, {'params': [tensor([[-0.1942,  1.2320, -2.2463],\n",
      "        [-1.8114,  0.4926, -0.2598],\n",
      "        [ 0.4626,  0.2851, -0.6369]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0}]\n",
      "state_dict before step:\n",
      " {'state': {140658301398544: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140658301398544]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [140658301396960]}]}\n",
      "state_dict after step:\n",
      " {'state': {140658301398544: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140658301398544]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [140658301396960]}]}\n",
      "----------done-----------\n",
      "load state_dict successfully\n",
      "{'state': {140658301398544: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140658301398544]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [140658301396960]}]}\n",
      "\n",
      "{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}\n",
      "\n",
      "defaultdict(<class 'dict'>, {tensor([[-0.6967, -0.2344],\n",
      "        [-0.1577, -0.7651]], requires_grad=True): {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}})\n",
      "\n",
      "[{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [tensor([[-0.6967, -0.2344],\n",
      "        [-0.1577, -0.7651]], requires_grad=True)]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [tensor([[-0.1942,  1.2320, -2.2463],\n",
      "        [-1.8114,  0.4926, -0.2598],\n",
      "        [ 0.4626,  0.2851, -0.6369]], requires_grad=True)]}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置权重，服从正态分布  --> 2 x 2\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "# 设置梯度为全1矩阵  --> 2 x 2\n",
    "weight.grad = torch.ones((2, 2))\n",
    "# 输出现有的weight和data\n",
    "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight before step:\\n{}\".format(weight.grad))\n",
    "# 实例化优化器\n",
    "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "# 进行一步操作\n",
    "optimizer.step()\n",
    "# 查看进行一步后的值，梯度\n",
    "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
    "# 权重清零\n",
    "optimizer.zero_grad()\n",
    "# 检验权重是否为0\n",
    "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))\n",
    "# 输出参数\n",
    "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
    "# 查看参数位置，optimizer和weight的位置一样，我觉得这里可以参考Python是基于值管理\n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    "# 添加参数：weight2\n",
    "weight2 = torch.randn((3, 3), requires_grad=True)\n",
    "optimizer.add_param_group({\"params\": weight2, 'lr': 0.0001, 'nesterov': True})\n",
    "# 查看现有的参数\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    "# 查看当前状态信息\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "print(\"state_dict before step:\\n\", opt_state_dict)\n",
    "# 进行5次step操作\n",
    "for _ in range(50):\n",
    "    optimizer.step()\n",
    "# 输出现有状态信息\n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "# 保存参数信息\n",
    "torch.save(optimizer.state_dict(),os.path.join(r\"./\", \"optimizer_state_dict.pkl\"))\n",
    "print(\"----------done-----------\")\n",
    "# 加载参数信息\n",
    "state_dict = torch.load(r\"./optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
    "# 输出最后属性信息\n",
    "print(\"\\n{}\".format(optimizer.defaults))\n",
    "print(\"\\n{}\".format(optimizer.state))\n",
    "print(\"\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 注意：\n",
    "\n",
    "1. 每个优化器都是一个类，我们一定要进行实例化才能使用，比如下方实现：\n",
    "\n",
    "```python\n",
    "class Net(nn.Moddule):\n",
    "    ···\n",
    "net = Net()\n",
    "optim = torch.optim.SGD(net.parameters(),lr=lr)\n",
    "optim.step()\n",
    "```\n",
    "\n",
    "2. optimizer在一个神经网络的epoch中需要实现下面两个步骤：\n",
    "   1. 梯度置零\n",
    "   2. 梯度更新\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-5)\n",
    "for epoch in range(EPOCH):\n",
    "\t...\n",
    "\toptimizer.zero_grad()  #梯度置零\n",
    "\tloss = ...             #计算loss\n",
    "\tloss.backward()        #BP反向传播\n",
    "\toptimizer.step()       #梯度更新\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.5  实验\n",
    "\n",
    "为了更好的帮大家了解优化器，我们对PyTorch中的优化器进行了一个小测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据生成\n",
    "a = torch.linspace(-1, 1, 1000)\n",
    "# 升维操作\n",
    "x = torch.unsqueeze(a, dim=1)\n",
    "y = x.pow(2) + 0.1 * torch.normal(torch.zeros(*x.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**数据分布曲线**：\n",
    "\n",
    "![](./figures/3.6.1.png)\n",
    "\n",
    "**网络结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(1, 20)\n",
    "        self.predict = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这部分是测试图，纵坐标代表Loss，横坐标代表的是Step：\n",
    "\n",
    "![](./figures/3.6.2.png)\n",
    "\n",
    "在上面的图片上，曲线下降的趋势和对应的steps代表了在这轮数据，模型下的收敛速度\n",
    "\n",
    "**注意:**\n",
    "\n",
    "优化器的选择是需要根据模型进行改变的，不存在绝对的好坏之分，我们需要多进行一些测试。\n",
    "\n",
    "后续会添加SparseAdam，LBFGS这两个优化器的可视化结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和评估\n",
    "\n",
    "完成了上述设定后就可以加载数据开始训练模型了。首先应该设置模型的状态：如果是训练状态，那么模型的参数应该支持反向传播的修改；如果是验证/测试状态，则不应该修改模型参数。在PyTorch中，模型的状态设置非常简便，如下的两个操作二选一即可：\n",
    "\n",
    "```python\n",
    "model.train()   # 训练状态\n",
    "model.eval()   # 验证/测试状态\n",
    "```\n",
    "\n",
    "我们前面在DataLoader构建完成后介绍了如何从中读取数据，在训练过程中使用类似的操作即可，区别在于此时要用for循环读取DataLoader中的全部数据。\n",
    "\n",
    "```python\n",
    "for data, label in train_loader:\n",
    "```\n",
    "\n",
    "之后将数据放到GPU上用于后续计算，此处以.cuda()为例\n",
    "\n",
    "```python\n",
    "data, label = data.cuda(), label.cuda()\n",
    "```\n",
    "\n",
    "开始用当前批次数据做训练时，应当先将优化器的梯度置零：\n",
    "\n",
    "```python\n",
    "optimizer.zero_grad()\n",
    "```\n",
    "\n",
    "之后将data送入模型中训练：\n",
    "\n",
    "```python\n",
    "output = model(data)\n",
    "```\n",
    "\n",
    "根据预先定义的criterion计算损失函数：\n",
    "\n",
    "```python\n",
    "loss = criterion(output, label)\n",
    "```\n",
    "\n",
    "将loss反向传播回网络：\n",
    "\n",
    "```python\n",
    "loss.backward()\n",
    "```\n",
    "\n",
    "使用优化器更新模型参数：\n",
    "\n",
    "```python\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "这样一个训练过程就完成了，后续还可以计算模型准确率等指标，这部分会在下一节的图像分类实战中加以介绍。\n",
    "\n",
    "验证/测试的流程基本与训练过程一致，不同点在于：\n",
    "\n",
    "- 需要预先设置torch.no_grad，以及将model调至eval模式\n",
    "- 不需要将优化器的梯度置零\n",
    "- 不需要将loss反向回传到网络\n",
    "- 不需要更新optimizer\n",
    "\n",
    "一个完整的训练过程如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(label, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对应的，一个完整的验证过程如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):       \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            preds = torch.argmax(output, 1)\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "            running_accu += torch.sum(preds == label.data)\n",
    "    val_loss = val_loss/len(val_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
