{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习案例一 （幸福感预测）\n",
    "\n",
    "### 背景介绍\n",
    "\n",
    "幸福感是一个古老而深刻的话题，是人类世代追求的方向。与幸福感相关的因素成千上万、因人而异，大如国计民生，小如路边烤红薯，都会对幸福感产生影响。这些错综复杂的因素中，我们能找到其中的共性，一窥幸福感的要义吗？\n",
    "\n",
    "另外，在社会科学领域，幸福感的研究占有重要的位置。这个涉及了哲学、心理学、社会学、经济学等多方学科的话题复杂而有趣；同时与大家生活息息相关，每个人对幸福感都有自己的衡量标准。如果能发现影响幸福感的共性，生活中是不是将多一些乐趣；如果能找到影响幸福感的政策因素，便能优化资源配置来提升国民的幸福感。目前社会科学研究注重变量的可解释性和未来政策的落地，主要采用了线性回归和逻辑回归的方法，在收入、健康、职业、社交关系、休闲方式等经济人口因素；以及政府公共服务、宏观经济环境、税负等宏观因素上有了一系列的推测和发现。\n",
    "\n",
    "该案例为幸福感预测这一经典课题，希望在现有社会科学研究外有其他维度的算法尝试，结合多学科各自优势，挖掘潜在的影响因素，发现更多可解释、可理解的相关关系。\n",
    "\n",
    "具体来说，该案例就是一个数据挖掘类型的比赛——幸福感预测的baseline。具体来说，我们需要使用包括个体变量（性别、年龄、地域、职业、健康、婚姻与政治面貌等等）、家庭变量（父母、配偶、子女、家庭资本等等）、社会态度（公平、信用、公共服务等等）等139维度的信息来预测其对幸福感的影响。\n",
    "\n",
    "我们的数据来源于国家官方的《中国综合社会调查（CGSS）》文件中的调查结果中的数据，数据来源可靠可依赖:)\n",
    "\n",
    "### 数据信息\n",
    "赛题要求使用以上 **139** 维的特征，使用 **8000** 余组数据进行对于个人幸福感的预测（预测值为1，2，3，4，5，其中1代表幸福感最低，5代表幸福感最高）。\n",
    "因为考虑到变量个数较多，部分变量间关系复杂，数据分为完整版和精简版两类。可从精简版入手熟悉赛题后，使用完整版挖掘更多信息。在这里我直接使用了完整版的数据。赛题也给出了index文件中包含每个变量对应的问卷题目，以及变量取值的含义；survey文件中为原版问卷，作为补充以方便理解问题背景。\n",
    "\n",
    "### 评价指标\n",
    "最终的评价指标为均方误差MSE，即：\n",
    "$$Score = \\frac{1}{n} \\sum_1 ^n (y_i - y ^*)^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import ElasticNet as en\n",
    "from sklearn.kernel_ridge import KernelRidge as kr\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold,GroupKFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') #消除warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", parse_dates=['survey_time'],encoding='latin-1') \n",
    "test = pd.read_csv(\"data/test.csv\", parse_dates=['survey_time'],encoding='latin-1') #latin-1向下兼容ASCII\n",
    "train = train[train[\"happiness\"]!=-8].reset_index(drop=True)\n",
    "train_data_copy = train.copy() #删去\"happiness\" 为-8的行\n",
    "target_col = \"happiness\" #目标列\n",
    "target = train_data_copy[target_col]\n",
    "del train_data_copy[target_col] #去除目标列\n",
    "\n",
    "data = pd.concat([train_data_copy,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看数据的基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7988.000000\n",
       "mean        3.867927\n",
       "std         0.818717\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.happiness.describe() #数据的基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "首先需要对于数据中的连续出现的负数值进行处理。由于数据中的负数值只有-1，-2，-3，-8这几种数值，所以它们进行分别的操作，实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make feature +5\n",
    "#csv中有复数值：-1、-2、-3、-8，将他们视为有问题的特征，但是不删去\n",
    "def getres1(row):\n",
    "    return len([x for x in row.values if type(x)==int and x<0])\n",
    "\n",
    "def getres2(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-8])\n",
    "\n",
    "def getres3(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-1])\n",
    "\n",
    "def getres4(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-2])\n",
    "\n",
    "def getres5(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-3])\n",
    "\n",
    "#检查数据\n",
    "data['neg1'] = data[data.columns].apply(lambda row:getres1(row),axis=1)\n",
    "data.loc[data['neg1']>20,'neg1'] = 20  #平滑处理,最多出现20次\n",
    "\n",
    "data['neg2'] = data[data.columns].apply(lambda row:getres2(row),axis=1)\n",
    "data['neg3'] = data[data.columns].apply(lambda row:getres3(row),axis=1)\n",
    "data['neg4'] = data[data.columns].apply(lambda row:getres4(row),axis=1)\n",
    "data['neg5'] = data[data.columns].apply(lambda row:getres5(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "填充缺失值，在这里我采取的方式是将缺失值补全，使用fillna(value)，其中value的数值根据具体的情况来确定。例如将大部分缺失信息认为是零，将家庭成员数认为是1，将家庭收入这个特征认为是66365，即所有家庭的收入平均值。部分实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填充缺失值 共25列 去掉4列 填充21列\n",
    "#以下的列都是缺省的，视情况填补\n",
    "data['work_status'] = data['work_status'].fillna(0)\n",
    "data['work_yr'] = data['work_yr'].fillna(0)\n",
    "data['work_manage'] = data['work_manage'].fillna(0)\n",
    "data['work_type'] = data['work_type'].fillna(0)\n",
    "\n",
    "data['edu_yr'] = data['edu_yr'].fillna(0)\n",
    "data['edu_status'] = data['edu_status'].fillna(0)\n",
    "\n",
    "data['s_work_type'] = data['s_work_type'].fillna(0)\n",
    "data['s_work_status'] = data['s_work_status'].fillna(0)\n",
    "data['s_political'] = data['s_political'].fillna(0)\n",
    "data['s_hukou'] = data['s_hukou'].fillna(0)\n",
    "data['s_income'] = data['s_income'].fillna(0)\n",
    "data['s_birth'] = data['s_birth'].fillna(0)\n",
    "data['s_edu'] = data['s_edu'].fillna(0)\n",
    "data['s_work_exper'] = data['s_work_exper'].fillna(0)\n",
    "\n",
    "data['minor_child'] = data['minor_child'].fillna(0)\n",
    "data['marital_now'] = data['marital_now'].fillna(0)\n",
    "data['marital_1st'] = data['marital_1st'].fillna(0)\n",
    "data['social_neighbor']=data['social_neighbor'].fillna(0)\n",
    "data['social_friend']=data['social_friend'].fillna(0)\n",
    "data['hukou_loc']=data['hukou_loc'].fillna(1) #最少为1，表示户口\n",
    "data['family_income']=data['family_income'].fillna(66365) #删除问题值后的平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除此之外，还有特殊格式的信息需要另外处理，比如与时间有关的信息，这里主要分为两部分进行处理：首先是将“连续”的年龄，进行分层处理，即划分年龄段，具体地在这里我们将年龄分为了6个区间。其次是计算具体的年龄，在Excel表格中，只有出生年月以及调查时间等信息，我们根据此计算出每一位调查者的真实年龄。具体实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#144+1 =145\n",
    "#继续进行特殊的列进行数据处理\n",
    "#读happiness_index.xlsx\n",
    "data['survey_time'] = pd.to_datetime(data['survey_time'], format='%Y-%m-%d',errors='coerce')#防止时间格式不同的报错errors='coerce‘\n",
    "data['survey_time'] = data['survey_time'].dt.year #仅仅是year，方便计算年龄\n",
    "data['age'] = data['survey_time']-data['birth']\n",
    "# print(data['age'],data['survey_time'],data['birth'])\n",
    "#年龄分层 145+1=146\n",
    "bins = [0,17,26,34,50,63,100]\n",
    "data['age_bin'] = pd.cut(data['age'], bins, labels=[0,1,2,3,4,5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里因为家庭的收入是连续值，所以不能再使用取众数的方法进行处理，这里就直接使用了均值进行缺失值的补全。第三种方法是使用我们日常生活中的真实情况，例如“宗教信息”特征为负数的认为是“不信仰宗教”，并认为“参加宗教活动的频率”为1，即没有参加过宗教活动，主观的进行补全，这也是我在这一步骤中使用最多的一种方式。就像我自己填表一样，这里我全部都使用了我自己的想法进行缺省值的补全。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对‘宗教’处理\n",
    "data.loc[data['religion']<0,'religion'] = 1 #1为不信仰宗教\n",
    "data.loc[data['religion_freq']<0,'religion_freq'] = 1 #1为从来没有参加过\n",
    "#对‘教育程度’处理\n",
    "data.loc[data['edu']<0,'edu'] = 4 #初中\n",
    "data.loc[data['edu_status']<0,'edu_status'] = 0\n",
    "data.loc[data['edu_yr']<0,'edu_yr'] = 0\n",
    "#对‘个人收入’处理\n",
    "data.loc[data['income']<0,'income'] = 0 #认为无收入\n",
    "#对‘政治面貌’处理\n",
    "data.loc[data['political']<0,'political'] = 1 #认为是群众\n",
    "#对体重处理\n",
    "data.loc[(data['weight_jin']<=80)&(data['height_cm']>=160),'weight_jin']= data['weight_jin']*2\n",
    "data.loc[data['weight_jin']<=60,'weight_jin']= data['weight_jin']*2  #个人的想法，哈哈哈，没有60斤的成年人吧\n",
    "#对身高处理\n",
    "data.loc[data['height_cm']<150,'height_cm'] = 150 #成年人的实际情况\n",
    "#对‘健康’处理\n",
    "data.loc[data['health']<0,'health'] = 4 #认为是比较健康\n",
    "data.loc[data['health_problem']<0,'health_problem'] = 4\n",
    "#对‘沮丧’处理\n",
    "data.loc[data['depression']<0,'depression'] = 4 #一般人都是很少吧\n",
    "#对‘媒体’处理\n",
    "data.loc[data['media_1']<0,'media_1'] = 1 #都是从不\n",
    "data.loc[data['media_2']<0,'media_2'] = 1\n",
    "data.loc[data['media_3']<0,'media_3'] = 1\n",
    "data.loc[data['media_4']<0,'media_4'] = 1\n",
    "data.loc[data['media_5']<0,'media_5'] = 1\n",
    "data.loc[data['media_6']<0,'media_6'] = 1\n",
    "#对‘空闲活动’处理\n",
    "data.loc[data['leisure_1']<0,'leisure_1'] = 1 #都是根据自己的想法\n",
    "data.loc[data['leisure_2']<0,'leisure_2'] = 5\n",
    "data.loc[data['leisure_3']<0,'leisure_3'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用众数（代码中使用mode()来实现异常值的修正），由于这里的特征是空闲活动，所以采用众数对于缺失值进行处理比较合理。具体的代码参考如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['leisure_4']<0,'leisure_4'] = data['leisure_4'].mode() #取众数\n",
    "data.loc[data['leisure_5']<0,'leisure_5'] = data['leisure_5'].mode()\n",
    "data.loc[data['leisure_6']<0,'leisure_6'] = data['leisure_6'].mode()\n",
    "data.loc[data['leisure_7']<0,'leisure_7'] = data['leisure_7'].mode()\n",
    "data.loc[data['leisure_8']<0,'leisure_8'] = data['leisure_8'].mode()\n",
    "data.loc[data['leisure_9']<0,'leisure_9'] = data['leisure_9'].mode()\n",
    "data.loc[data['leisure_10']<0,'leisure_10'] = data['leisure_10'].mode()\n",
    "data.loc[data['leisure_11']<0,'leisure_11'] = data['leisure_11'].mode()\n",
    "data.loc[data['leisure_12']<0,'leisure_12'] = data['leisure_12'].mode()\n",
    "data.loc[data['socialize']<0,'socialize'] = 2 #很少\n",
    "data.loc[data['relax']<0,'relax'] = 4 #经常\n",
    "data.loc[data['learn']<0,'learn'] = 1 #从不，哈哈哈哈\n",
    "#对‘社交’处理\n",
    "data.loc[data['social_neighbor']<0,'social_neighbor'] = 0\n",
    "data.loc[data['social_friend']<0,'social_friend'] = 0\n",
    "data.loc[data['socia_outing']<0,'socia_outing'] = 1\n",
    "data.loc[data['neighbor_familiarity']<0,'social_neighbor']= 4\n",
    "#对‘社会公平性’处理\n",
    "data.loc[data['equity']<0,'equity'] = 4\n",
    "#对‘社会等级’处理\n",
    "data.loc[data['class_10_before']<0,'class_10_before'] = 3\n",
    "data.loc[data['class']<0,'class'] = 5\n",
    "data.loc[data['class_10_after']<0,'class_10_after'] = 5\n",
    "data.loc[data['class_14']<0,'class_14'] = 2\n",
    "#对‘工作情况’处理\n",
    "data.loc[data['work_status']<0,'work_status'] = 0\n",
    "data.loc[data['work_yr']<0,'work_yr'] = 0\n",
    "data.loc[data['work_manage']<0,'work_manage'] = 0\n",
    "data.loc[data['work_type']<0,'work_type'] = 0\n",
    "#对‘社会保障’处理\n",
    "data.loc[data['insur_1']<0,'insur_1'] = 1\n",
    "data.loc[data['insur_2']<0,'insur_2'] = 1\n",
    "data.loc[data['insur_3']<0,'insur_3'] = 1\n",
    "data.loc[data['insur_4']<0,'insur_4'] = 1\n",
    "data.loc[data['insur_1']==0,'insur_1'] = 0\n",
    "data.loc[data['insur_2']==0,'insur_2'] = 0\n",
    "data.loc[data['insur_3']==0,'insur_3'] = 0\n",
    "data.loc[data['insur_4']==0,'insur_4'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取均值进行缺失值的补全（代码实现为means()），在这里因为家庭的收入是连续值，所以不能再使用取众数的方法进行处理，这里就直接使用了均值进行缺失值的补全。具体的代码参考如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对家庭情况处理\n",
    "family_income_mean = data['family_income'].mean()\n",
    "data.loc[data['family_income']<0,'family_income'] = family_income_mean\n",
    "data.loc[data['family_m']<0,'family_m'] = 2\n",
    "data.loc[data['family_status']<0,'family_status'] = 3\n",
    "data.loc[data['house']<0,'house'] = 1\n",
    "data.loc[data['car']<0,'car'] = 0\n",
    "data.loc[data['car']==2,'car'] = 0\n",
    "data.loc[data['son']<0,'son'] = 1\n",
    "data.loc[data['daughter']<0,'daughter'] = 0\n",
    "data.loc[data['minor_child']<0,'minor_child'] = 0\n",
    "#对‘婚姻’处理\n",
    "data.loc[data['marital_1st']<0,'marital_1st'] = 0\n",
    "data.loc[data['marital_now']<0,'marital_now'] = 0\n",
    "#对‘配偶’处理\n",
    "data.loc[data['s_birth']<0,'s_birth'] = 0\n",
    "data.loc[data['s_edu']<0,'s_edu'] = 0\n",
    "data.loc[data['s_political']<0,'s_political'] = 0\n",
    "data.loc[data['s_hukou']<0,'s_hukou'] = 0\n",
    "data.loc[data['s_income']<0,'s_income'] = 0\n",
    "data.loc[data['s_work_type']<0,'s_work_type'] = 0\n",
    "data.loc[data['s_work_status']<0,'s_work_status'] = 0\n",
    "data.loc[data['s_work_exper']<0,'s_work_exper'] = 0\n",
    "#对‘父母情况’处理\n",
    "data.loc[data['f_birth']<0,'f_birth'] = 1945\n",
    "data.loc[data['f_edu']<0,'f_edu'] = 1\n",
    "data.loc[data['f_political']<0,'f_political'] = 1\n",
    "data.loc[data['f_work_14']<0,'f_work_14'] = 2\n",
    "data.loc[data['m_birth']<0,'m_birth'] = 1940\n",
    "data.loc[data['m_edu']<0,'m_edu'] = 1\n",
    "data.loc[data['m_political']<0,'m_political'] = 1\n",
    "data.loc[data['m_work_14']<0,'m_work_14'] = 2\n",
    "#和同龄人相比社会经济地位\n",
    "data.loc[data['status_peer']<0,'status_peer'] = 2\n",
    "#和3年前比社会经济地位\n",
    "data.loc[data['status_3_before']<0,'status_3_before'] = 2\n",
    "#对‘观点’处理\n",
    "data.loc[data['view']<0,'view'] = 4\n",
    "#对期望年收入处理\n",
    "data.loc[data['inc_ability']<=0,'inc_ability']= 2\n",
    "inc_exp_mean = data['inc_exp'].mean()\n",
    "data.loc[data['inc_exp']<=0,'inc_exp']= inc_exp_mean #取均值\n",
    "\n",
    "#部分特征处理，取众数\n",
    "for i in range(1,9+1):\n",
    "    data.loc[data['public_service_'+str(i)]<0,'public_service_'+str(i)] = data['public_service_'+str(i)].dropna().mode().values\n",
    "for i in range(1,13+1):\n",
    "    data.loc[data['trust_'+str(i)]<0,'trust_'+str(i)] = data['trust_'+str(i)].dropna().mode().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增广\n",
    "\n",
    "这一步，我们需要进一步分析每一个特征之间的关系，从而进行数据增广。经过思考，这里我添加了如下的特征：第一次结婚年龄、最近结婚年龄、是否再婚、配偶年龄、配偶年龄差、各种收入比（与配偶之间的收入比、十年后预期收入与现在收入之比等等）、收入与住房面积比（其中也包括10年后期望收入等等各种情况）、社会阶级（10年后的社会阶级、14年后的社会阶级等等）、悠闲指数、满意指数、信任指数等等。除此之外，我还考虑了对于同一省、市、县进行了归一化。例如同一省市内的收入的平均值等以及一个个体相对于同省、市、县其他人的各个指标的情况。同时也考虑了对于同龄人之间的相互比较，即在同龄人中的收入情况、健康情况等等。具体的实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一次结婚年龄 147\n",
    "data['marital_1stbir'] = data['marital_1st'] - data['birth'] \n",
    "#最近结婚年龄 148\n",
    "data['marital_nowtbir'] = data['marital_now'] - data['birth'] \n",
    "#是否再婚 149\n",
    "data['mar'] = data['marital_nowtbir'] - data['marital_1stbir']\n",
    "#配偶年龄 150\n",
    "data['marital_sbir'] = data['marital_now']-data['s_birth']\n",
    "#配偶年龄差 151\n",
    "data['age_'] = data['marital_nowtbir'] - data['marital_sbir'] \n",
    "\n",
    "#收入比 151+7 =158\n",
    "data['income/s_income'] = data['income']/(data['s_income']+1)\n",
    "data['income+s_income'] = data['income']+(data['s_income']+1)\n",
    "data['income/family_income'] = data['income']/(data['family_income']+1)\n",
    "data['all_income/family_income'] = (data['income']+data['s_income'])/(data['family_income']+1)\n",
    "data['income/inc_exp'] = data['income']/(data['inc_exp']+1)\n",
    "data['family_income/m'] = data['family_income']/(data['family_m']+0.01)\n",
    "data['income/m'] = data['income']/(data['family_m']+0.01)\n",
    "\n",
    "#收入/面积比 158+4=162\n",
    "data['income/floor_area'] = data['income']/(data['floor_area']+0.01)\n",
    "data['all_income/floor_area'] = (data['income']+data['s_income'])/(data['floor_area']+0.01)\n",
    "data['family_income/floor_area'] = data['family_income']/(data['floor_area']+0.01)\n",
    "data['floor_area/m'] = data['floor_area']/(data['family_m']+0.01)\n",
    "\n",
    "#class 162+3=165\n",
    "data['class_10_diff'] = (data['class_10_after'] - data['class'])\n",
    "data['class_diff'] = data['class'] - data['class_10_before']\n",
    "data['class_14_diff'] = data['class'] - data['class_14']\n",
    "#悠闲指数 166\n",
    "leisure_fea_lis = ['leisure_'+str(i) for i in range(1,13)]\n",
    "data['leisure_sum'] = data[leisure_fea_lis].sum(axis=1) #skew\n",
    "#满意指数 167\n",
    "public_service_fea_lis = ['public_service_'+str(i) for i in range(1,10)]\n",
    "data['public_service_sum'] = data[public_service_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#信任指数 168\n",
    "trust_fea_lis = ['trust_'+str(i) for i in range(1,14)]\n",
    "data['trust_sum'] = data[trust_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "#province mean 168+13=181\n",
    "data['province_income_mean'] = data.groupby(['province'])['income'].transform('mean').values\n",
    "data['province_family_income_mean'] = data.groupby(['province'])['family_income'].transform('mean').values\n",
    "data['province_equity_mean'] = data.groupby(['province'])['equity'].transform('mean').values\n",
    "data['province_depression_mean'] = data.groupby(['province'])['depression'].transform('mean').values\n",
    "data['province_floor_area_mean'] = data.groupby(['province'])['floor_area'].transform('mean').values\n",
    "data['province_health_mean'] = data.groupby(['province'])['health'].transform('mean').values\n",
    "data['province_class_10_diff_mean'] = data.groupby(['province'])['class_10_diff'].transform('mean').values\n",
    "data['province_class_mean'] = data.groupby(['province'])['class'].transform('mean').values\n",
    "data['province_health_problem_mean'] = data.groupby(['province'])['health_problem'].transform('mean').values\n",
    "data['province_family_status_mean'] = data.groupby(['province'])['family_status'].transform('mean').values\n",
    "data['province_leisure_sum_mean'] = data.groupby(['province'])['leisure_sum'].transform('mean').values\n",
    "data['province_public_service_sum_mean'] = data.groupby(['province'])['public_service_sum'].transform('mean').values\n",
    "data['province_trust_sum_mean'] = data.groupby(['province'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#city   mean 181+13=194\n",
    "data['city_income_mean'] = data.groupby(['city'])['income'].transform('mean').values\n",
    "data['city_family_income_mean'] = data.groupby(['city'])['family_income'].transform('mean').values\n",
    "data['city_equity_mean'] = data.groupby(['city'])['equity'].transform('mean').values\n",
    "data['city_depression_mean'] = data.groupby(['city'])['depression'].transform('mean').values\n",
    "data['city_floor_area_mean'] = data.groupby(['city'])['floor_area'].transform('mean').values\n",
    "data['city_health_mean'] = data.groupby(['city'])['health'].transform('mean').values\n",
    "data['city_class_10_diff_mean'] = data.groupby(['city'])['class_10_diff'].transform('mean').values\n",
    "data['city_class_mean'] = data.groupby(['city'])['class'].transform('mean').values\n",
    "data['city_health_problem_mean'] = data.groupby(['city'])['health_problem'].transform('mean').values\n",
    "data['city_family_status_mean'] = data.groupby(['city'])['family_status'].transform('mean').values\n",
    "data['city_leisure_sum_mean'] = data.groupby(['city'])['leisure_sum'].transform('mean').values\n",
    "data['city_public_service_sum_mean'] = data.groupby(['city'])['public_service_sum'].transform('mean').values\n",
    "data['city_trust_sum_mean'] = data.groupby(['city'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#county  mean 194 + 13 = 207\n",
    "data['county_income_mean'] = data.groupby(['county'])['income'].transform('mean').values\n",
    "data['county_family_income_mean'] = data.groupby(['county'])['family_income'].transform('mean').values\n",
    "data['county_equity_mean'] = data.groupby(['county'])['equity'].transform('mean').values\n",
    "data['county_depression_mean'] = data.groupby(['county'])['depression'].transform('mean').values\n",
    "data['county_floor_area_mean'] = data.groupby(['county'])['floor_area'].transform('mean').values\n",
    "data['county_health_mean'] = data.groupby(['county'])['health'].transform('mean').values\n",
    "data['county_class_10_diff_mean'] = data.groupby(['county'])['class_10_diff'].transform('mean').values\n",
    "data['county_class_mean'] = data.groupby(['county'])['class'].transform('mean').values\n",
    "data['county_health_problem_mean'] = data.groupby(['county'])['health_problem'].transform('mean').values\n",
    "data['county_family_status_mean'] = data.groupby(['county'])['family_status'].transform('mean').values\n",
    "data['county_leisure_sum_mean'] = data.groupby(['county'])['leisure_sum'].transform('mean').values\n",
    "data['county_public_service_sum_mean'] = data.groupby(['county'])['public_service_sum'].transform('mean').values\n",
    "data['county_trust_sum_mean'] = data.groupby(['county'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#ratio 相比同省 207 + 13 =220\n",
    "data['income/province'] = data['income']/(data['province_income_mean'])                                      \n",
    "data['family_income/province'] = data['family_income']/(data['province_family_income_mean'])   \n",
    "data['equity/province'] = data['equity']/(data['province_equity_mean'])       \n",
    "data['depression/province'] = data['depression']/(data['province_depression_mean'])                                                \n",
    "data['floor_area/province'] = data['floor_area']/(data['province_floor_area_mean'])\n",
    "data['health/province'] = data['health']/(data['province_health_mean'])\n",
    "data['class_10_diff/province'] = data['class_10_diff']/(data['province_class_10_diff_mean'])\n",
    "data['class/province'] = data['class']/(data['province_class_mean'])\n",
    "data['health_problem/province'] = data['health_problem']/(data['province_health_problem_mean'])\n",
    "data['family_status/province'] = data['family_status']/(data['province_family_status_mean'])\n",
    "data['leisure_sum/province'] = data['leisure_sum']/(data['province_leisure_sum_mean'])\n",
    "data['public_service_sum/province'] = data['public_service_sum']/(data['province_public_service_sum_mean'])\n",
    "data['trust_sum/province'] = data['trust_sum']/(data['province_trust_sum_mean']+1)\n",
    "\n",
    "#ratio 相比同市 220 + 13 =233\n",
    "data['income/city'] = data['income']/(data['city_income_mean'])                                      \n",
    "data['family_income/city'] = data['family_income']/(data['city_family_income_mean'])   \n",
    "data['equity/city'] = data['equity']/(data['city_equity_mean'])       \n",
    "data['depression/city'] = data['depression']/(data['city_depression_mean'])                                                \n",
    "data['floor_area/city'] = data['floor_area']/(data['city_floor_area_mean'])\n",
    "data['health/city'] = data['health']/(data['city_health_mean'])\n",
    "data['class_10_diff/city'] = data['class_10_diff']/(data['city_class_10_diff_mean'])\n",
    "data['class/city'] = data['class']/(data['city_class_mean'])\n",
    "data['health_problem/city'] = data['health_problem']/(data['city_health_problem_mean'])\n",
    "data['family_status/city'] = data['family_status']/(data['city_family_status_mean'])\n",
    "data['leisure_sum/city'] = data['leisure_sum']/(data['city_leisure_sum_mean'])\n",
    "data['public_service_sum/city'] = data['public_service_sum']/(data['city_public_service_sum_mean'])\n",
    "data['trust_sum/city'] = data['trust_sum']/(data['city_trust_sum_mean'])\n",
    "\n",
    "#ratio 相比同个地区 233 + 13 =246\n",
    "data['income/county'] = data['income']/(data['county_income_mean'])                                      \n",
    "data['family_income/county'] = data['family_income']/(data['county_family_income_mean'])   \n",
    "data['equity/county'] = data['equity']/(data['county_equity_mean'])       \n",
    "data['depression/county'] = data['depression']/(data['county_depression_mean'])                                                \n",
    "data['floor_area/county'] = data['floor_area']/(data['county_floor_area_mean'])\n",
    "data['health/county'] = data['health']/(data['county_health_mean'])\n",
    "data['class_10_diff/county'] = data['class_10_diff']/(data['county_class_10_diff_mean'])\n",
    "data['class/county'] = data['class']/(data['county_class_mean'])\n",
    "data['health_problem/county'] = data['health_problem']/(data['county_health_problem_mean'])\n",
    "data['family_status/county'] = data['family_status']/(data['county_family_status_mean'])\n",
    "data['leisure_sum/county'] = data['leisure_sum']/(data['county_leisure_sum_mean'])\n",
    "data['public_service_sum/county'] = data['public_service_sum']/(data['county_public_service_sum_mean'])\n",
    "data['trust_sum/county'] = data['trust_sum']/(data['county_trust_sum_mean'])\n",
    "\n",
    "#age   mean 246+ 13 =259\n",
    "data['age_income_mean'] = data.groupby(['age'])['income'].transform('mean').values\n",
    "data['age_family_income_mean'] = data.groupby(['age'])['family_income'].transform('mean').values\n",
    "data['age_equity_mean'] = data.groupby(['age'])['equity'].transform('mean').values\n",
    "data['age_depression_mean'] = data.groupby(['age'])['depression'].transform('mean').values\n",
    "data['age_floor_area_mean'] = data.groupby(['age'])['floor_area'].transform('mean').values\n",
    "data['age_health_mean'] = data.groupby(['age'])['health'].transform('mean').values\n",
    "data['age_class_10_diff_mean'] = data.groupby(['age'])['class_10_diff'].transform('mean').values\n",
    "data['age_class_mean'] = data.groupby(['age'])['class'].transform('mean').values\n",
    "data['age_health_problem_mean'] = data.groupby(['age'])['health_problem'].transform('mean').values\n",
    "data['age_family_status_mean'] = data.groupby(['age'])['family_status'].transform('mean').values\n",
    "data['age_leisure_sum_mean'] = data.groupby(['age'])['leisure_sum'].transform('mean').values\n",
    "data['age_public_service_sum_mean'] = data.groupby(['age'])['public_service_sum'].transform('mean').values\n",
    "data['age_trust_sum_mean'] = data.groupby(['age'])['trust_sum'].transform('mean').values\n",
    "\n",
    "# 和同龄人相比259 + 13 =272\n",
    "data['income/age'] = data['income']/(data['age_income_mean'])                                      \n",
    "data['family_income/age'] = data['family_income']/(data['age_family_income_mean'])   \n",
    "data['equity/age'] = data['equity']/(data['age_equity_mean'])       \n",
    "data['depression/age'] = data['depression']/(data['age_depression_mean'])                                                \n",
    "data['floor_area/age'] = data['floor_area']/(data['age_floor_area_mean'])\n",
    "data['health/age'] = data['health']/(data['age_health_mean'])\n",
    "data['class_10_diff/age'] = data['class_10_diff']/(data['age_class_10_diff_mean'])\n",
    "data['class/age'] = data['class']/(data['age_class_mean'])\n",
    "data['health_problem/age'] = data['health_problem']/(data['age_health_problem_mean'])\n",
    "data['family_status/age'] = data['family_status']/(data['age_family_status_mean'])\n",
    "data['leisure_sum/age'] = data['leisure_sum']/(data['age_leisure_sum_mean'])\n",
    "data['public_service_sum/age'] = data['public_service_sum']/(data['age_public_service_sum_mean'])\n",
    "data['trust_sum/age'] = data['trust_sum']/(data['age_trust_sum_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过如上的操作后，最终我们的特征从一开始的131维，扩充为了272维的特征。接下来考虑特征工程、训练模型以及模型融合的工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10956, 272)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_type</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>depression/age</th>\n",
       "      <th>floor_area/age</th>\n",
       "      <th>health/age</th>\n",
       "      <th>class_10_diff/age</th>\n",
       "      <th>class/age</th>\n",
       "      <th>health_problem/age</th>\n",
       "      <th>family_status/age</th>\n",
       "      <th>leisure_sum/age</th>\n",
       "      <th>public_service_sum/age</th>\n",
       "      <th>trust_sum/age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>0.666638</td>\n",
       "      <td>0.925941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>1.344444</td>\n",
       "      <td>0.891344</td>\n",
       "      <td>1.359551</td>\n",
       "      <td>1.011792</td>\n",
       "      <td>1.130778</td>\n",
       "      <td>1.188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343537</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>1.150485</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>1.195762</td>\n",
       "      <td>1.055679</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>1.193204</td>\n",
       "      <td>0.803693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>0.642329</td>\n",
       "      <td>1.276353</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>1.199143</td>\n",
       "      <td>1.188329</td>\n",
       "      <td>1.162630</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>1.153810</td>\n",
       "      <td>1.300950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>1.116803</td>\n",
       "      <td>1.093645</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>1.117428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_type  province  city  county  survey_time  gender  birth  \\\n",
       "0   1            1        12    32      59         2015       1   1959   \n",
       "1   2            2        18    52      85         2015       1   1992   \n",
       "2   3            2        29    83     126         2015       2   1967   \n",
       "3   4            2        10    28      51         2015       2   1943   \n",
       "4   5            1         7    18      36         2015       2   1994   \n",
       "\n",
       "   nationality  religion      ...        depression/age  floor_area/age  \\\n",
       "0            1         1      ...              1.285211        0.410351   \n",
       "1            1         1      ...              0.733333        0.952824   \n",
       "2            1         0      ...              1.343537        0.972328   \n",
       "3            1         1      ...              1.111663        0.642329   \n",
       "4            1         1      ...              0.750000        0.587284   \n",
       "\n",
       "  health/age  class_10_diff/age  class/age  health_problem/age  \\\n",
       "0   0.848837           0.000000   0.683307            0.521429   \n",
       "1   1.179337           1.012552   1.344444            0.891344   \n",
       "2   1.150485           1.190955   1.195762            1.055679   \n",
       "3   1.276353           4.977778   1.199143            1.188329   \n",
       "4   1.177106           0.000000   0.236957            1.116803   \n",
       "\n",
       "   family_status/age  leisure_sum/age  public_service_sum/age  trust_sum/age  \n",
       "0           0.733668         0.724620                0.666638       0.925941  \n",
       "1           1.359551         1.011792                1.130778       1.188442  \n",
       "2           1.190955         0.966470                1.193204       0.803693  \n",
       "3           1.162630         0.899346                1.153810       1.300950  \n",
       "4           1.093645         1.045313                0.728161       1.117428  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还应该删去有效样本数很少的特征，例如负值太多的特征或者是缺失值太多的特征，这里我一共删除了包括“目前的最高教育程度”在内的9类特征，得到了最终的263维的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 263)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#272-9=263\n",
    "#删除数值特别少的和之前用过的特征\n",
    "del_list=['id','survey_time','edu_other','invest_other','property_other','join_party','province','city','county']\n",
    "use_feature = [clo for clo in data.columns if clo not in del_list]\n",
    "data.fillna(0,inplace=True) #还是补0\n",
    "train_shape = train.shape[0] #一共的数据量，训练集\n",
    "features = data[use_feature].columns #删除后所有的特征\n",
    "X_train_263 = data[:train_shape][use_feature].values\n",
    "y_train = target\n",
    "X_test_263 = data[train_shape:][use_feature].values\n",
    "X_train_263.shape #最终一种263个特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里选择了最重要的49个特征，作为除了以上263维特征外的另外一组特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_fea_49 = ['equity','depression','health','class','family_status','health_problem','class_10_after',\n",
    "           'equity/province','equity/city','equity/county',\n",
    "           'depression/province','depression/city','depression/county',\n",
    "           'health/province','health/city','health/county',\n",
    "           'class/province','class/city','class/county',\n",
    "           'family_status/province','family_status/city','family_status/county',\n",
    "           'family_income/province','family_income/city','family_income/county',\n",
    "           'floor_area/province','floor_area/city','floor_area/county',\n",
    "           'leisure_sum/province','leisure_sum/city','leisure_sum/county',\n",
    "           'public_service_sum/province','public_service_sum/city','public_service_sum/county',\n",
    "           'trust_sum/province','trust_sum/city','trust_sum/county',\n",
    "           'income/m','public_service_sum','class_diff','status_3_before','age_income_mean','age_floor_area_mean',\n",
    "           'weight_jin','height_cm',\n",
    "           'health/age','depression/age','equity/age','leisure_sum/age'\n",
    "          ]\n",
    "train_shape = train.shape[0]\n",
    "X_train_49 = data[:train_shape][imp_fea_49].values\n",
    "X_test_49 = data[train_shape:][imp_fea_49].values\n",
    "X_train_49.shape #最重要的49个特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择需要进行onehot编码的离散变量进行one-hot编码，再合成为第三类特征，共383维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 383)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fea = ['survey_type','gender','nationality','edu_status','political','hukou','hukou_loc','work_exper','work_status','work_type',\n",
    "           'work_manage','marital','s_political','s_hukou','s_work_exper','s_work_status','s_work_type','f_political','f_work_14',\n",
    "           'm_political','m_work_14']\n",
    "noc_fea = [clo for clo in use_feature if clo not in cat_fea]\n",
    "\n",
    "onehot_data = data[cat_fea].values\n",
    "enc = preprocessing.OneHotEncoder(categories = 'auto')\n",
    "oh_data=enc.fit_transform(onehot_data).toarray()\n",
    "oh_data.shape #变为onehot编码格式\n",
    "\n",
    "X_train_oh = oh_data[:train_shape,:]\n",
    "X_test_oh = oh_data[train_shape:,:]\n",
    "X_train_oh.shape #其中的训练集\n",
    "\n",
    "X_train_383 = np.column_stack([data[:train_shape][noc_fea].values,X_train_oh])#先是noc，再是cat_fea\n",
    "X_test_383 = np.column_stack([data[train_shape:][noc_fea].values,X_test_oh])\n",
    "X_train_383.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于此，我们构建完成了三种特征工程（训练数据集），其一是上面提取的最重要的49中特征，其中包括健康程度、社会阶级、在同龄人中的收入情况等等特征。其二是扩充后的263维特征（这里可以认为是初始特征）。其三是使用One-hot编码后的特征，这里要使用One-hot进行编码的原因在于，有部分特征为分离值，例如性别中男女，男为1，女为2，我们想使用One-hot将其变为男为0，女为1，来增强机器学习算法的鲁棒性能；再如民族这个特征，原本是1-56这56个数值，如果直接分类会让分类器的鲁棒性变差，所以使用One-hot编码将其变为6个特征进行非零即一的处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征建模\n",
    "\n",
    "首先我们对于原始的263维的特征，使用lightGBM进行处理，这里我们使用5折交叉验证的方法：\n",
    "\n",
    "1.lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.499759\tvalid_1's l2: 0.532511\n",
      "[1000]\ttraining's l2: 0.451529\tvalid_1's l2: 0.499127\n",
      "[1500]\ttraining's l2: 0.425443\tvalid_1's l2: 0.485366\n",
      "[2000]\ttraining's l2: 0.407395\tvalid_1's l2: 0.479303\n",
      "[2500]\ttraining's l2: 0.393001\tvalid_1's l2: 0.475556\n",
      "[3000]\ttraining's l2: 0.380761\tvalid_1's l2: 0.473666\n",
      "[3500]\ttraining's l2: 0.370005\tvalid_1's l2: 0.472563\n",
      "[4000]\ttraining's l2: 0.360215\tvalid_1's l2: 0.471631\n",
      "[4500]\ttraining's l2: 0.351235\tvalid_1's l2: 0.470938\n",
      "[5000]\ttraining's l2: 0.342828\tvalid_1's l2: 0.470683\n",
      "[5500]\ttraining's l2: 0.334901\tvalid_1's l2: 0.470155\n",
      "[6000]\ttraining's l2: 0.3274\tvalid_1's l2: 0.470072\n",
      "[6500]\ttraining's l2: 0.320153\tvalid_1's l2: 0.47005\n",
      "[7000]\ttraining's l2: 0.313311\tvalid_1's l2: 0.469912\n",
      "[7500]\ttraining's l2: 0.306748\tvalid_1's l2: 0.46995\n",
      "[8000]\ttraining's l2: 0.300336\tvalid_1's l2: 0.470026\n",
      "Early stopping, best iteration is:\n",
      "[7447]\ttraining's l2: 0.307448\tvalid_1's l2: 0.469826\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504322\tvalid_1's l2: 0.513628\n",
      "[1000]\ttraining's l2: 0.454889\tvalid_1's l2: 0.47926\n",
      "[1500]\ttraining's l2: 0.428783\tvalid_1's l2: 0.465975\n",
      "[2000]\ttraining's l2: 0.410928\tvalid_1's l2: 0.459213\n",
      "[2500]\ttraining's l2: 0.39726\tvalid_1's l2: 0.455058\n",
      "[3000]\ttraining's l2: 0.385428\tvalid_1's l2: 0.45243\n",
      "[3500]\ttraining's l2: 0.374844\tvalid_1's l2: 0.45074\n",
      "[4000]\ttraining's l2: 0.365252\tvalid_1's l2: 0.449328\n",
      "[4500]\ttraining's l2: 0.356333\tvalid_1's l2: 0.448423\n",
      "[5000]\ttraining's l2: 0.348003\tvalid_1's l2: 0.447458\n",
      "[5500]\ttraining's l2: 0.339994\tvalid_1's l2: 0.446682\n",
      "[6000]\ttraining's l2: 0.332355\tvalid_1's l2: 0.446153\n",
      "[6500]\ttraining's l2: 0.325106\tvalid_1's l2: 0.445942\n",
      "[7000]\ttraining's l2: 0.318209\tvalid_1's l2: 0.445729\n",
      "[7500]\ttraining's l2: 0.311488\tvalid_1's l2: 0.445203\n",
      "[8000]\ttraining's l2: 0.305185\tvalid_1's l2: 0.444862\n",
      "[8500]\ttraining's l2: 0.299025\tvalid_1's l2: 0.444872\n",
      "[9000]\ttraining's l2: 0.293039\tvalid_1's l2: 0.444637\n",
      "[9500]\ttraining's l2: 0.287237\tvalid_1's l2: 0.444412\n",
      "[10000]\ttraining's l2: 0.281718\tvalid_1's l2: 0.444121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l2: 0.281718\tvalid_1's l2: 0.444121\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.50317\tvalid_1's l2: 0.518027\n",
      "[1000]\ttraining's l2: 0.455064\tvalid_1's l2: 0.480542\n",
      "[1500]\ttraining's l2: 0.429866\tvalid_1's l2: 0.464074\n",
      "[2000]\ttraining's l2: 0.412419\tvalid_1's l2: 0.455414\n",
      "[2500]\ttraining's l2: 0.39819\tvalid_1's l2: 0.449861\n",
      "[3000]\ttraining's l2: 0.386279\tvalid_1's l2: 0.446579\n",
      "[3500]\ttraining's l2: 0.375505\tvalid_1's l2: 0.444652\n",
      "[4000]\ttraining's l2: 0.365722\tvalid_1's l2: 0.442958\n",
      "[4500]\ttraining's l2: 0.356747\tvalid_1's l2: 0.442154\n",
      "[5000]\ttraining's l2: 0.348329\tvalid_1's l2: 0.441595\n",
      "[5500]\ttraining's l2: 0.340206\tvalid_1's l2: 0.440923\n",
      "[6000]\ttraining's l2: 0.332514\tvalid_1's l2: 0.440634\n",
      "[6500]\ttraining's l2: 0.325136\tvalid_1's l2: 0.440318\n",
      "[7000]\ttraining's l2: 0.318154\tvalid_1's l2: 0.440439\n",
      "Early stopping, best iteration is:\n",
      "[6645]\ttraining's l2: 0.323052\tvalid_1's l2: 0.440181\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504279\tvalid_1's l2: 0.512194\n",
      "[1000]\ttraining's l2: 0.455536\tvalid_1's l2: 0.477492\n",
      "[1500]\ttraining's l2: 0.429192\tvalid_1's l2: 0.465315\n",
      "[2000]\ttraining's l2: 0.411059\tvalid_1's l2: 0.459402\n",
      "[2500]\ttraining's l2: 0.396766\tvalid_1's l2: 0.455937\n",
      "[3000]\ttraining's l2: 0.384721\tvalid_1's l2: 0.453696\n",
      "[3500]\ttraining's l2: 0.3741\tvalid_1's l2: 0.452256\n",
      "[4000]\ttraining's l2: 0.364289\tvalid_1's l2: 0.45118\n",
      "[4500]\ttraining's l2: 0.355254\tvalid_1's l2: 0.450291\n",
      "[5000]\ttraining's l2: 0.346816\tvalid_1's l2: 0.44973\n",
      "[5500]\ttraining's l2: 0.338933\tvalid_1's l2: 0.449181\n",
      "[6000]\ttraining's l2: 0.331387\tvalid_1's l2: 0.448914\n",
      "[6500]\ttraining's l2: 0.32404\tvalid_1's l2: 0.448702\n",
      "[7000]\ttraining's l2: 0.317208\tvalid_1's l2: 0.448468\n",
      "[7500]\ttraining's l2: 0.310593\tvalid_1's l2: 0.448375\n",
      "[8000]\ttraining's l2: 0.304157\tvalid_1's l2: 0.448561\n",
      "Early stopping, best iteration is:\n",
      "[7381]\ttraining's l2: 0.312154\tvalid_1's l2: 0.448282\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503075\tvalid_1's l2: 0.519874\n",
      "[1000]\ttraining's l2: 0.454635\tvalid_1's l2: 0.484867\n",
      "[1500]\ttraining's l2: 0.42871\tvalid_1's l2: 0.471137\n",
      "[2000]\ttraining's l2: 0.410716\tvalid_1's l2: 0.464987\n",
      "[2500]\ttraining's l2: 0.396241\tvalid_1's l2: 0.46153\n",
      "[3000]\ttraining's l2: 0.383972\tvalid_1's l2: 0.459225\n",
      "[3500]\ttraining's l2: 0.372947\tvalid_1's l2: 0.458011\n",
      "[4000]\ttraining's l2: 0.362992\tvalid_1's l2: 0.457356\n",
      "[4500]\ttraining's l2: 0.353769\tvalid_1's l2: 0.457291\n",
      "[5000]\ttraining's l2: 0.345122\tvalid_1's l2: 0.457313\n",
      "[5500]\ttraining's l2: 0.33702\tvalid_1's l2: 0.45702\n",
      "[6000]\ttraining's l2: 0.329492\tvalid_1's l2: 0.456985\n",
      "[6500]\ttraining's l2: 0.322039\tvalid_1's l2: 0.457153\n",
      "Early stopping, best iteration is:\n",
      "[5850]\ttraining's l2: 0.33172\tvalid_1's l2: 0.45687\n",
      "CV score: 0.45185567\n"
     ]
    }
   ],
   "source": [
    "##### lgb_263 #\n",
    "#lightGBM决策树\n",
    "lgb_263_param = {\n",
    "'num_leaves': 7, \n",
    "'min_data_in_leaf': 20, #叶子可能具有的最小记录数\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.003,\n",
    "\"boosting\": \"gbdt\", #用gbdt算法\n",
    "\"feature_fraction\": 0.18, #例如 0.18时，意味着在每次迭代中随机选择18％的参数来建树\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.55, #每次迭代时用的数据比例\n",
    "\"bagging_seed\": 14,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l1\": 0.1005,\n",
    "\"lambda_l2\": 0.1996, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)   #交叉切分：5\n",
    "oof_lgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_lgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_263[val_idx], y_train[val_idx])#train:val=4:1\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_263 = lgb.train(lgb_263_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 800)\n",
    "    oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx], num_iteration=lgb_263.best_iteration)\n",
    "    predictions_lgb_263 += lgb_263.predict(X_test_263, num_iteration=lgb_263.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我使用已经训练完的lightGBM的模型进行特征重要性的判断以及可视化，从结果我们可以看出，排在重要性第一位的是health/age，就是同龄人中的健康程度，与我们主观的看法基本一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2016 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------特征重要性\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "df = pd.DataFrame(data[use_feature].columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb_263.feature_importance())\n",
    "df = df.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df.head(50))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面，我们使用常见的机器学习方法，对于263维特征进行建模：\n",
    "\n",
    "2.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[12:49:18] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:49:18] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40426\tvalid_data-rmse:3.38323\n",
      "[500]\ttrain-rmse:0.40646\tvalid_data-rmse:0.70634\n",
      "[1000]\ttrain-rmse:0.27163\tvalid_data-rmse:0.70830\n",
      "[1168]\ttrain-rmse:0.23626\tvalid_data-rmse:0.70892\n",
      "fold n°2\n",
      "[12:49:28] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:49:28] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39813\tvalid_data-rmse:3.40800\n",
      "[500]\ttrain-rmse:0.40704\tvalid_data-rmse:0.69045\n",
      "[1000]\ttrain-rmse:0.27316\tvalid_data-rmse:0.69246\n",
      "[1078]\ttrain-rmse:0.25727\tvalid_data-rmse:0.69293\n",
      "fold n°3\n",
      "[12:49:36] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:49:36] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40180\tvalid_data-rmse:3.39296\n",
      "[500]\ttrain-rmse:0.41015\tvalid_data-rmse:0.66312\n",
      "[983]\ttrain-rmse:0.27576\tvalid_data-rmse:0.66656\n",
      "fold n°4\n",
      "[12:49:44] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:49:44] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40237\tvalid_data-rmse:3.39011\n",
      "[500]\ttrain-rmse:0.41350\tvalid_data-rmse:0.66706\n",
      "[1000]\ttrain-rmse:0.27488\tvalid_data-rmse:0.66675\n",
      "[1223]\ttrain-rmse:0.22959\tvalid_data-rmse:0.66728\n",
      "fold n°5\n",
      "[12:49:53] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:49:53] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39342\tvalid_data-rmse:3.42633\n",
      "[500]\ttrain-rmse:0.41482\tvalid_data-rmse:0.64649\n",
      "[1000]\ttrain-rmse:0.27847\tvalid_data-rmse:0.64658\n",
      "[1263]\ttrain-rmse:0.22589\tvalid_data-rmse:0.64745\n",
      "CV score: 0.45449155\n"
     ]
    }
   ],
   "source": [
    "##### xgb_263\n",
    "#xgboost\n",
    "xgb_263_params = {'eta': 0.02,  #lr\n",
    "              'max_depth': 6,  \n",
    "              'min_child_weight':3,#最小叶子节点样本权重和\n",
    "              'gamma':0, #指定节点分裂所需的最小损失函数下降值。\n",
    "              'subsample': 0.7,  #控制对于每棵树，随机采样的比例\n",
    "              'colsample_bytree': 0.3,  #用来控制每棵随机采样的列数的占比 (每一列是一个特征)。\n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_xgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_263 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_263_params)\n",
    "    oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]), ntree_limit=xgb_263.best_ntree_limit)\n",
    "    predictions_xgb_263 += xgb_263.predict(xgb.DMatrix(X_test_263), ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. RandomForestRegressor随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   21.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   21.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   20.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   20.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.47773236\n"
     ]
    }
   ],
   "source": [
    "#RandomForestRegressor随机森林\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_rfr_263 = np.zeros(len(X_train_263))\n",
    "predictions_rfr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    rfr_263 = rfr(n_estimators=1600,max_depth=9, min_samples_leaf=9, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.25,verbose=1,n_jobs=-1)\n",
    "    #verbose = 0 为不在标准输出流输出日志信息\n",
    "#verbose = 1 为输出进度条记录\n",
    "#verbose = 2 为每个epoch输出一行记录\n",
    "    rfr_263.fit(tr_x,tr_y)\n",
    "    oof_rfr_263[val_idx] = rfr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_rfr_263 += rfr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_rfr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. GradientBoostingRegressor梯度提升决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6486           0.0033           28.62s\n",
      "         2           0.6553           0.0034           28.42s\n",
      "         3           0.6730           0.0032           28.28s\n",
      "         4           0.6620           0.0032           28.09s\n",
      "         5           0.6413           0.0030           27.86s\n",
      "         6           0.6432           0.0029           27.78s\n",
      "         7           0.6336           0.0028           27.67s\n",
      "         8           0.6353           0.0029           27.63s\n",
      "         9           0.6123           0.0031           27.60s\n",
      "        10           0.6281           0.0027           27.56s\n",
      "        20           0.6040           0.0020           27.22s\n",
      "        30           0.5584           0.0018           26.31s\n",
      "        40           0.5311           0.0018           25.46s\n",
      "        50           0.5095           0.0014           24.68s\n",
      "        60           0.5058           0.0011           23.92s\n",
      "        70           0.4587           0.0009           23.17s\n",
      "        80           0.4634           0.0007           22.43s\n",
      "        90           0.4496           0.0007           21.75s\n",
      "       100           0.4161           0.0005           21.04s\n",
      "       200           0.3492           0.0001           14.00s\n",
      "       300           0.2951           0.0000            6.99s\n",
      "       400           0.2726          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6647           0.0035           28.21s\n",
      "         2           0.6623           0.0034           28.09s\n",
      "         3           0.6527           0.0035           27.92s\n",
      "         4           0.6603           0.0031           27.63s\n",
      "         5           0.6352           0.0031           27.75s\n",
      "         6           0.6296           0.0034           27.66s\n",
      "         7           0.6273           0.0031           27.44s\n",
      "         8           0.6434           0.0028           27.30s\n",
      "         9           0.6427           0.0026           27.38s\n",
      "        10           0.6163           0.0027           27.34s\n",
      "        20           0.6073           0.0022           26.49s\n",
      "        30           0.5497           0.0021           25.79s\n",
      "        40           0.5455           0.0017           25.09s\n",
      "        50           0.5218           0.0014           24.41s\n",
      "        60           0.4981           0.0013           23.71s\n",
      "        70           0.4660           0.0010           23.04s\n",
      "        80           0.4494           0.0007           22.38s\n",
      "        90           0.4271           0.0007           21.67s\n",
      "       100           0.4359           0.0004           20.96s\n",
      "       200           0.3422           0.0001           13.97s\n",
      "       300           0.2909          -0.0000            6.99s\n",
      "       400           0.2726          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6632           0.0035           27.14s\n",
      "         2           0.6469           0.0035           27.29s\n",
      "         3           0.6634           0.0033           27.65s\n",
      "         4           0.6502           0.0033           27.64s\n",
      "         5           0.6750           0.0029           27.70s\n",
      "         6           0.6410           0.0031           27.58s\n",
      "         7           0.6492           0.0030           27.58s\n",
      "         8           0.6181           0.0032           27.54s\n",
      "         9           0.6448           0.0030           27.64s\n",
      "        10           0.6394           0.0028           27.58s\n",
      "        20           0.5879           0.0026           26.56s\n",
      "        30           0.5578           0.0020           25.78s\n",
      "        40           0.5227           0.0016           25.13s\n",
      "        50           0.5110           0.0014           24.35s\n",
      "        60           0.4849           0.0011           23.65s\n",
      "        70           0.4618           0.0010           22.96s\n",
      "        80           0.4619           0.0008           22.28s\n",
      "        90           0.4570           0.0007           21.59s\n",
      "       100           0.4232           0.0006           20.88s\n",
      "       200           0.3485           0.0001           13.87s\n",
      "       300           0.3038           0.0000            6.94s\n",
      "       400           0.2661           0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6796           0.0031           27.74s\n",
      "         2           0.6704           0.0034           27.45s\n",
      "         3           0.6933           0.0029           27.53s\n",
      "         4           0.6573           0.0033           27.53s\n",
      "         5           0.6584           0.0031           27.56s\n",
      "         6           0.6288           0.0031           27.47s\n",
      "         7           0.6410           0.0031           27.32s\n",
      "         8           0.6382           0.0029           27.20s\n",
      "         9           0.6257           0.0030           27.18s\n",
      "        10           0.6376           0.0031           27.10s\n",
      "        20           0.5978           0.0020           26.36s\n",
      "        30           0.5554           0.0019           25.69s\n",
      "        40           0.5373           0.0017           25.03s\n",
      "        50           0.4986           0.0015           24.33s\n",
      "        60           0.4996           0.0011           23.66s\n",
      "        70           0.4736           0.0008           22.95s\n",
      "        80           0.4552           0.0007           22.24s\n",
      "        90           0.4353           0.0007           21.56s\n",
      "       100           0.4157           0.0007           20.87s\n",
      "       200           0.3475          -0.0000           13.92s\n",
      "       300           0.3040          -0.0000            6.96s\n",
      "       400           0.2603          -0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6650           0.0036           28.60s\n",
      "         2           0.6797           0.0030           28.05s\n",
      "         3           0.6639           0.0032           27.96s\n",
      "         4           0.6472           0.0030           27.80s\n",
      "         5           0.6484           0.0032           27.61s\n",
      "         6           0.6396           0.0029           27.54s\n",
      "         7           0.6337           0.0031           27.43s\n",
      "         8           0.6150           0.0032           27.44s\n",
      "         9           0.6473           0.0027           27.50s\n",
      "        10           0.6301           0.0030           27.50s\n",
      "        20           0.5989           0.0021           26.53s\n",
      "        30           0.5726           0.0019           25.83s\n",
      "        40           0.5274           0.0014           25.18s\n",
      "        50           0.5189           0.0013           24.43s\n",
      "        60           0.4958           0.0010           23.72s\n",
      "        70           0.4884           0.0008           23.04s\n",
      "        80           0.4582           0.0007           22.35s\n",
      "        90           0.4271           0.0006           21.65s\n",
      "       100           0.4377           0.0007           20.93s\n",
      "       200           0.3473           0.0001           13.93s\n",
      "       300           0.2982          -0.0000            6.96s\n",
      "       400           0.2573           0.0000            0.00s\n",
      "CV score: 0.45714865\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingRegressor梯度提升决策树\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_263 = np.zeros(train_shape)\n",
    "predictions_gbr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_263 = gbr(n_estimators=400, learning_rate=0.01,subsample=0.65,max_depth=7, min_samples_leaf=20,\n",
    "            max_features=0.22,verbose=1)\n",
    "    gbr_263.fit(tr_x,tr_y)\n",
    "    oof_gbr_263[val_idx] = gbr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_gbr_263 += gbr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ExtraTreesRegressor 极端随机森林回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.48633994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesRegressor 极端随机森林回归\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_etr_263 = np.zeros(train_shape)\n",
    "predictions_etr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    etr_263 = etr(n_estimators=1000,max_depth=8, min_samples_leaf=12, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.4,verbose=1,n_jobs=-1)\n",
    "    etr_263.fit(tr_x,tr_y)\n",
    "    oof_etr_263[val_idx] = etr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_etr_263 += etr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_etr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们得到了以上5种模型的预测结果以及模型架构及参数。其中在每一种特征工程中，进行5折的交叉验证，并重复两次（Kernel Ridge Regression，核脊回归），取得每一个特征数下的模型的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44903628873500817"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack2 = np.vstack([oof_lgb_263,oof_xgb_263,oof_gbr_263,oof_rfr_263,oof_etr_263]).transpose()\n",
    "# transpose()函数的作用就是调换x,y,z的位置,也就是数组的索引值\n",
    "test_stack2 = np.vstack([predictions_lgb_263, predictions_xgb_263,predictions_gbr_263,predictions_rfr_263,predictions_etr_263]).transpose()\n",
    "\n",
    "#交叉验证:5折，重复2次\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack2 = np.zeros(train_stack2.shape[0])\n",
    "predictions_lr2 = np.zeros(test_stack2.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack2,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack2[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack2[val_idx], target.iloc[val_idx].values\n",
    "    #Kernel Ridge Regression\n",
    "    lr2 = kr()\n",
    "    lr2.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack2[val_idx] = lr2.predict(val_data)\n",
    "    predictions_lr2 += lr2.predict(test_stack2) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们对于49维的数据进行与上述263维数据相同的操作\n",
    "\n",
    "1.lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.471019\tvalid_1's l2: 0.494326\n",
      "[2000]\ttraining's l2: 0.430666\tvalid_1's l2: 0.474748\n",
      "[3000]\ttraining's l2: 0.408207\tvalid_1's l2: 0.469893\n",
      "[4000]\ttraining's l2: 0.390556\tvalid_1's l2: 0.46828\n",
      "[5000]\ttraining's l2: 0.375144\tvalid_1's l2: 0.46747\n",
      "[6000]\ttraining's l2: 0.361309\tvalid_1's l2: 0.467255\n",
      "Early stopping, best iteration is:\n",
      "[5457]\ttraining's l2: 0.368666\tvalid_1's l2: 0.467017\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.471402\tvalid_1's l2: 0.493843\n",
      "[2000]\ttraining's l2: 0.43052\tvalid_1's l2: 0.474481\n",
      "[3000]\ttraining's l2: 0.407758\tvalid_1's l2: 0.469914\n",
      "[4000]\ttraining's l2: 0.389637\tvalid_1's l2: 0.46848\n",
      "[5000]\ttraining's l2: 0.374293\tvalid_1's l2: 0.467984\n",
      "[6000]\ttraining's l2: 0.360368\tvalid_1's l2: 0.46791\n",
      "[7000]\ttraining's l2: 0.347628\tvalid_1's l2: 0.468419\n",
      "Early stopping, best iteration is:\n",
      "[6259]\ttraining's l2: 0.356974\tvalid_1's l2: 0.467782\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.474022\tvalid_1's l2: 0.487747\n",
      "[2000]\ttraining's l2: 0.433151\tvalid_1's l2: 0.464339\n",
      "[3000]\ttraining's l2: 0.410082\tvalid_1's l2: 0.460623\n",
      "[4000]\ttraining's l2: 0.392208\tvalid_1's l2: 0.460245\n",
      "Early stopping, best iteration is:\n",
      "[3588]\ttraining's l2: 0.399063\tvalid_1's l2: 0.459916\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.467292\tvalid_1's l2: 0.508077\n",
      "[2000]\ttraining's l2: 0.427587\tvalid_1's l2: 0.489703\n",
      "[3000]\ttraining's l2: 0.405916\tvalid_1's l2: 0.48449\n",
      "[4000]\ttraining's l2: 0.388609\tvalid_1's l2: 0.48129\n",
      "[5000]\ttraining's l2: 0.373794\tvalid_1's l2: 0.479316\n",
      "[6000]\ttraining's l2: 0.360553\tvalid_1's l2: 0.477517\n",
      "[7000]\ttraining's l2: 0.348442\tvalid_1's l2: 0.476095\n",
      "[8000]\ttraining's l2: 0.337103\tvalid_1's l2: 0.474862\n",
      "[9000]\ttraining's l2: 0.326261\tvalid_1's l2: 0.474065\n",
      "[10000]\ttraining's l2: 0.31619\tvalid_1's l2: 0.47324\n",
      "[11000]\ttraining's l2: 0.306605\tvalid_1's l2: 0.47275\n",
      "[12000]\ttraining's l2: 0.297541\tvalid_1's l2: 0.472706\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[12000]\ttraining's l2: 0.297541\tvalid_1's l2: 0.472706\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.468538\tvalid_1's l2: 0.504093\n",
      "[2000]\ttraining's l2: 0.428006\tvalid_1's l2: 0.486731\n",
      "[3000]\ttraining's l2: 0.405601\tvalid_1's l2: 0.482439\n",
      "[4000]\ttraining's l2: 0.387814\tvalid_1's l2: 0.480658\n",
      "[5000]\ttraining's l2: 0.372535\tvalid_1's l2: 0.479483\n",
      "[6000]\ttraining's l2: 0.358699\tvalid_1's l2: 0.479134\n",
      "[7000]\ttraining's l2: 0.346094\tvalid_1's l2: 0.479209\n",
      "Early stopping, best iteration is:\n",
      "[6272]\ttraining's l2: 0.355147\tvalid_1's l2: 0.479113\n",
      "CV score: 0.46930531\n"
     ]
    }
   ],
   "source": [
    "##### lgb_49\n",
    "lgb_49_param = {\n",
    "'num_leaves': 9,\n",
    "'min_data_in_leaf': 23,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.002,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.45,\n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.65,\n",
    "\"bagging_seed\": 15,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)   \n",
    "oof_lgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_lgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 12000\n",
    "    lgb_49 = lgb.train(lgb_49_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "    oof_lgb_49[val_idx] = lgb_49.predict(X_train_49[val_idx], num_iteration=lgb_49.best_iteration)\n",
    "    predictions_lgb_49 += lgb_49.predict(X_test_49, num_iteration=lgb_49.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[14:22:03] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:03] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40425\tvalid_data-rmse:3.38305\n",
      "[500]\ttrain-rmse:0.52642\tvalid_data-rmse:0.72154\n",
      "[939]\ttrain-rmse:0.44592\tvalid_data-rmse:0.72357\n",
      "fold n°2\n",
      "[14:22:06] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:06] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39822\tvalid_data-rmse:3.40777\n",
      "[500]\ttrain-rmse:0.52808\tvalid_data-rmse:0.70487\n",
      "[1000]\ttrain-rmse:0.43702\tvalid_data-rmse:0.70675\n",
      "[1011]\ttrain-rmse:0.43518\tvalid_data-rmse:0.70669\n",
      "fold n°3\n",
      "[14:22:09] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:09] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40187\tvalid_data-rmse:3.39309\n",
      "[500]\ttrain-rmse:0.53426\tvalid_data-rmse:0.67022\n",
      "[969]\ttrain-rmse:0.44586\tvalid_data-rmse:0.67288\n",
      "fold n°4\n",
      "[14:22:12] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:12] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40248\tvalid_data-rmse:3.39001\n",
      "[500]\ttrain-rmse:0.53268\tvalid_data-rmse:0.67872\n",
      "[1000]\ttrain-rmse:0.44322\tvalid_data-rmse:0.68120\n",
      "[1105]\ttrain-rmse:0.42565\tvalid_data-rmse:0.68271\n",
      "fold n°5\n",
      "[14:22:15] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:15] WARNING: /tmp/pip-install-wegy69mc/xgboost/build/temp.linux-aarch64-3.6/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39345\tvalid_data-rmse:3.42626\n",
      "[500]\ttrain-rmse:0.53558\tvalid_data-rmse:0.66200\n",
      "[1000]\ttrain-rmse:0.44183\tvalid_data-rmse:0.66241\n",
      "[1500]\ttrain-rmse:0.36901\tvalid_data-rmse:0.66787\n",
      "[1506]\ttrain-rmse:0.36828\tvalid_data-rmse:0.66784\n",
      "CV score: 0.47218782\n"
     ]
    }
   ],
   "source": [
    "##### xgb_49\n",
    "xgb_49_params = {'eta': 0.02, \n",
    "              'max_depth': 5, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.35, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_xgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_49 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_49_params)\n",
    "    oof_xgb_49[val_idx] = xgb_49.predict(xgb.DMatrix(X_train_49[val_idx]), ntree_limit=xgb_49.best_ntree_limit)\n",
    "    predictions_xgb_49 += xgb_49.predict(xgb.DMatrix(X_test_49), ntree_limit=xgb_49.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. GradientBoostingRegressor梯度提升决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6577           0.0032           18.74s\n",
      "         2           0.6615           0.0031           18.29s\n",
      "         3           0.6653           0.0033           18.21s\n",
      "         4           0.6541           0.0029           18.29s\n",
      "         5           0.6364           0.0031           18.29s\n",
      "         6           0.6490           0.0029           18.26s\n",
      "         7           0.6491           0.0028           18.25s\n",
      "         8           0.6531           0.0029           18.18s\n",
      "         9           0.6287           0.0031           18.20s\n",
      "        10           0.6246           0.0029           18.14s\n",
      "        20           0.5984           0.0027           17.59s\n",
      "        30           0.5651           0.0018           17.23s\n",
      "        40           0.5442           0.0017           16.90s\n",
      "        50           0.5349           0.0012           16.54s\n",
      "        60           0.5080           0.0011           16.22s\n",
      "        70           0.5103           0.0010           15.93s\n",
      "        80           0.4867           0.0007           15.62s\n",
      "        90           0.4908           0.0006           15.31s\n",
      "       100           0.4526           0.0005           15.01s\n",
      "       200           0.3914           0.0000           11.98s\n",
      "       300           0.3638          -0.0000            8.99s\n",
      "       400           0.3503          -0.0000            6.00s\n",
      "       500           0.3415          -0.0001            3.01s\n",
      "       600           0.3159          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6596           0.0035           17.82s\n",
      "         2           0.6641           0.0029           17.89s\n",
      "         3           0.6700           0.0034           17.96s\n",
      "         4           0.6630           0.0033           18.01s\n",
      "         5           0.6526           0.0032           17.96s\n",
      "         6           0.6496           0.0030           18.00s\n",
      "         7           0.6564           0.0029           17.94s\n",
      "         8           0.6576           0.0027           17.95s\n",
      "         9           0.6439           0.0027           17.88s\n",
      "        10           0.6350           0.0027           17.89s\n",
      "        20           0.5960           0.0024           17.36s\n",
      "        30           0.5596           0.0021           17.11s\n",
      "        40           0.5425           0.0017           16.83s\n",
      "        50           0.5396           0.0014           16.50s\n",
      "        60           0.5141           0.0013           16.22s\n",
      "        70           0.5010           0.0009           15.95s\n",
      "        80           0.4823           0.0008           15.65s\n",
      "        90           0.4674           0.0008           15.34s\n",
      "       100           0.4635           0.0005           15.01s\n",
      "       200           0.3885           0.0001           11.96s\n",
      "       300           0.3791          -0.0000            9.00s\n",
      "       400           0.3447           0.0000            6.01s\n",
      "       500           0.3243          -0.0000            3.01s\n",
      "       600           0.3099          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6779           0.0035           18.02s\n",
      "         2           0.6806           0.0036           17.75s\n",
      "         3           0.6538           0.0033           17.66s\n",
      "         4           0.6609           0.0031           17.64s\n",
      "         5           0.6363           0.0031           17.72s\n",
      "         6           0.6537           0.0028           17.76s\n",
      "         7           0.6647           0.0028           17.72s\n",
      "         8           0.6253           0.0032           17.67s\n",
      "         9           0.6276           0.0032           17.65s\n",
      "        10           0.6202           0.0025           17.58s\n",
      "        20           0.5971           0.0027           17.19s\n",
      "        30           0.5785           0.0020           16.90s\n",
      "        40           0.5534           0.0015           16.64s\n",
      "        50           0.5305           0.0011           16.31s\n",
      "        60           0.5016           0.0013           16.02s\n",
      "        70           0.5066           0.0009           15.74s\n",
      "        80           0.4810           0.0008           15.43s\n",
      "        90           0.4719           0.0006           15.12s\n",
      "       100           0.4685           0.0005           14.83s\n",
      "       200           0.3917           0.0000           11.86s\n",
      "       300           0.3563          -0.0000            8.93s\n",
      "       400           0.3423          -0.0000            5.97s\n",
      "       500           0.3241          -0.0000            2.99s\n",
      "       600           0.3012          -0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6728           0.0032           18.27s\n",
      "         2           0.6623           0.0032           18.21s\n",
      "         3           0.6331           0.0034           18.22s\n",
      "         4           0.6497           0.0033           18.22s\n",
      "         5           0.6608           0.0031           18.17s\n",
      "         6           0.6254           0.0031           18.21s\n",
      "         7           0.6416           0.0029           18.10s\n",
      "         8           0.6531           0.0031           18.11s\n",
      "         9           0.6344           0.0028           18.09s\n",
      "        10           0.6395           0.0030           18.05s\n",
      "        20           0.6205           0.0021           17.59s\n",
      "        30           0.5577           0.0020           17.21s\n",
      "        40           0.5526           0.0016           16.86s\n",
      "        50           0.5362           0.0013           16.54s\n",
      "        60           0.5239           0.0010           16.25s\n",
      "        70           0.4844           0.0010           15.93s\n",
      "        80           0.4941           0.0006           15.60s\n",
      "        90           0.4713           0.0007           15.28s\n",
      "       100           0.4582           0.0005           14.98s\n",
      "       200           0.4019          -0.0001           11.95s\n",
      "       300           0.3667          -0.0000            8.97s\n",
      "       400           0.3381          -0.0000            5.99s\n",
      "       500           0.3253          -0.0000            3.00s\n",
      "       600           0.3093          -0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6552           0.0033           17.62s\n",
      "         2           0.6599           0.0032           17.89s\n",
      "         3           0.6511           0.0033           17.93s\n",
      "         4           0.6687           0.0032           17.76s\n",
      "         5           0.6526           0.0032           17.84s\n",
      "         6           0.6325           0.0030           17.91s\n",
      "         7           0.6497           0.0030           17.90s\n",
      "         8           0.6570           0.0029           17.86s\n",
      "         9           0.6378           0.0030           17.92s\n",
      "        10           0.6570           0.0027           17.90s\n",
      "        20           0.6113           0.0022           17.46s\n",
      "        30           0.5737           0.0020           17.09s\n",
      "        40           0.5322           0.0016           16.76s\n",
      "        50           0.5194           0.0013           16.47s\n",
      "        60           0.5107           0.0011           16.18s\n",
      "        70           0.5056           0.0009           16.19s\n",
      "        80           0.4805           0.0008           15.82s\n",
      "        90           0.4816           0.0006           15.49s\n",
      "       100           0.4490           0.0005           15.17s\n",
      "       200           0.4026           0.0000           12.02s\n",
      "       300           0.3668           0.0000            9.01s\n",
      "       400           0.3352          -0.0001            6.01s\n",
      "       500           0.3262          -0.0000            3.01s\n",
      "       600           0.3189          -0.0001            0.00s\n",
      "CV score: 0.47116900\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_49 = np.zeros(train_shape)\n",
    "predictions_gbr_49 = np.zeros(len(X_test_49))\n",
    "#GradientBoostingRegressor梯度提升决策树\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_49 = gbr(n_estimators=600, learning_rate=0.01,subsample=0.65,max_depth=6, min_samples_leaf=20,\n",
    "            max_features=0.35,verbose=1)\n",
    "    gbr_49.fit(tr_x,tr_y)\n",
    "    oof_gbr_49[val_idx] = gbr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_gbr_49 += gbr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们得到了以上3种模型的基于49个特征的预测结果以及模型架构及参数。其中在每一种特征工程中，进行5折的交叉验证，并重复两次（Kernel Ridge Regression，核脊回归），取得每一个特征数下的模型的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46817155627702345"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack3 = np.vstack([oof_lgb_49,oof_xgb_49,oof_gbr_49]).transpose()\n",
    "test_stack3 = np.vstack([predictions_lgb_49, predictions_xgb_49,predictions_gbr_49]).transpose()\n",
    "#\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack3 = np.zeros(train_stack3.shape[0])\n",
    "predictions_lr3 = np.zeros(test_stack3.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack3,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack3[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack3[val_idx], target.iloc[val_idx].values\n",
    "        #Kernel Ridge Regression\n",
    "    lr3 = kr()\n",
    "    lr3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack3[val_idx] = lr3.predict(val_data)\n",
    "    predictions_lr3 += lr3.predict(test_stack3) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack3) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们对于383维的数据进行与上述263以及49维数据相同的操作\n",
    "\n",
    "1. Kernel Ridge Regression 基于核的岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.51443500\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_383 = np.zeros(train_shape)\n",
    "predictions_kr_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #Kernel Ridge Regression 岭回归\n",
    "    kr_383 = kr()\n",
    "    kr_383.fit(tr_x,tr_y)\n",
    "    oof_kr_383[val_idx] = kr_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_kr_383 += kr_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用普通岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48687670\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_383 = np.zeros(train_shape)\n",
    "predictions_ridge_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #使用岭回归\n",
    "    ridge_383 = Ridge(alpha=1200)\n",
    "    ridge_383.fit(tr_x,tr_y)\n",
    "    oof_ridge_383[val_idx] = ridge_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_ridge_383 += ridge_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 使用ElasticNet 弹性网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53296555\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_383 = np.zeros(train_shape)\n",
    "predictions_en_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #ElasticNet 弹性网络\n",
    "    en_383 = en(alpha=1.0,l1_ratio=0.06)\n",
    "    en_383.fit(tr_x,tr_y)\n",
    "    oof_en_383[val_idx] = en_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_en_383 += en_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 使用BayesianRidge 贝叶斯岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48717330\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_383 = np.zeros(train_shape)\n",
    "predictions_br_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    #BayesianRidge 贝叶斯回归\n",
    "    br_383 = br()\n",
    "    br_383.fit(tr_x,tr_y)\n",
    "    oof_br_383[val_idx] = br_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_br_383 += br_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们得到了以上4种模型的基于383个特征的预测结果以及模型架构及参数。其中在每一种特征工程中，进行5折的交叉验证，并重复两次（LinearRegression简单的线性回归），取得每一个特征数下的模型的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48769378240207956"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack1 = np.vstack([oof_br_383,oof_kr_383,oof_en_383,oof_ridge_383]).transpose()\n",
    "test_stack1 = np.vstack([predictions_br_383, predictions_kr_383,predictions_en_383,predictions_ridge_383]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack1 = np.zeros(train_stack1.shape[0])\n",
    "predictions_lr1 = np.zeros(test_stack1.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack1,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack1[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack1[val_idx], target.iloc[val_idx].values\n",
    "    # LinearRegression简单的线性回归\n",
    "    lr1 = lr()\n",
    "    lr1.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack1[val_idx] = lr1.predict(val_data)\n",
    "    predictions_lr1 += lr1.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于49维的特征是最重要的特征，所以这里考虑增加更多的模型进行49维特征的数据的构建工作。\n",
    "1. KernelRidge 核岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.50255192\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_49 = np.zeros(train_shape)\n",
    "predictions_kr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_49 = kr()\n",
    "    kr_49.fit(tr_x,tr_y)\n",
    "    oof_kr_49[val_idx] = kr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_kr_49 += kr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ridge 岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49451286\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_49 = np.zeros(train_shape)\n",
    "predictions_ridge_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_49 = Ridge(alpha=6)\n",
    "    ridge_49.fit(tr_x,tr_y)\n",
    "    oof_ridge_49[val_idx] = ridge_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_ridge_49 += ridge_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. BayesianRidge 贝叶斯岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49534595\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_49 = np.zeros(train_shape)\n",
    "predictions_br_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_49 = br()\n",
    "    br_49.fit(tr_x,tr_y)\n",
    "    oof_br_49[val_idx] = br_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_br_49 += br_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ElasticNet 弹性网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53841695\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_49 = np.zeros(train_shape)\n",
    "predictions_en_49 = np.zeros(len(X_test_49))\n",
    "#\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_49 = en(alpha=1.0,l1_ratio=0.05)\n",
    "    en_49.fit(tr_x,tr_y)\n",
    "    oof_en_49[val_idx] = en_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_en_49 += en_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们得到了以上4种新模型的基于49个特征的预测结果以及模型架构及参数。其中在每一种特征工程中，进行5折的交叉验证，并重复两次（LinearRegression简单的线性回归），取得每一个特征数下的模型的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4949149641125251"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack4 = np.vstack([oof_br_49,oof_kr_49,oof_en_49,oof_ridge_49]).transpose()\n",
    "test_stack4 = np.vstack([predictions_br_49, predictions_kr_49,predictions_en_49,predictions_ridge_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack4 = np.zeros(train_stack4.shape[0])\n",
    "predictions_lr4 = np.zeros(test_stack4.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack4,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack4[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack4[val_idx], target.iloc[val_idx].values\n",
    "    #LinearRegression\n",
    "    lr4 = lr()\n",
    "    lr4.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack4[val_idx] = lr4.predict(val_data)\n",
    "    predictions_lr4 += lr4.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合\n",
    "\n",
    "这里对于上述四种集成学习的模型的预测结果进行加权的求和，得到最终的结果，当然这种方式是很不准确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45377126870685175"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#和下面作对比\n",
    "mean_squared_error(target.values, 0.7*(0.6*oof_stack2 + 0.4*oof_stack3)+0.3*(0.55*oof_stack1+0.45*oof_stack4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更好的方式是将以上的4中集成学习模型再次进行集成学习的训练，这里直接使用LinearRegression简单线性回归的进行集成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4490884601800237"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack5 = np.vstack([oof_stack1,oof_stack2,oof_stack3,oof_stack4]).transpose()\n",
    "test_stack5 = np.vstack([predictions_lr1, predictions_lr2,predictions_lr3,predictions_lr4]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack5 = np.zeros(train_stack5.shape[0])\n",
    "predictions_lr5= np.zeros(test_stack5.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack5,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack5[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack5[val_idx], target.iloc[val_idx].values\n",
    "    #LinearRegression\n",
    "    lr5 = lr()\n",
    "    lr5.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack5[val_idx] = lr5.predict(val_data)\n",
    "    predictions_lr5 += lr5.predict(test_stack5) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果保存\n",
    "\n",
    "进行index的读取工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879419\n",
       "std         0.462852\n",
       "min         1.690768\n",
       "25%         3.664202\n",
       "50%         3.950750\n",
       "75%         4.188872\n",
       "max         5.086290\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example = pd.read_csv('data/submit_example.csv',sep=',',encoding='latin-1')\n",
    "\n",
    "submit_example['happiness'] = predictions_lr5\n",
    "\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行结果保存，这里我们预测出的值是1-5的连续值，但是我们的ground truth是整数值，所以为了进一步优化我们的结果，我们对于结果进行了整数解的近似，并保存到了csv文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879397\n",
       "std         0.462733\n",
       "min         1.690768\n",
       "25%         3.664202\n",
       "50%         3.950750\n",
       "75%         4.188872\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example.loc[submit_example['happiness']>4.96,'happiness']= 5\n",
    "submit_example.loc[submit_example['happiness']<=1.04,'happiness']= 1\n",
    "submit_example.loc[(submit_example['happiness']>1.96)&(submit_example['happiness']<2.04),'happiness']= 2\n",
    "\n",
    "submit_example.to_csv(\"result/submision.csv\",index=False)\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家可以对于model的参数进行更进一步的调整，例如使用网格搜索的方法。这留给大家做进一步的思考喽～"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
