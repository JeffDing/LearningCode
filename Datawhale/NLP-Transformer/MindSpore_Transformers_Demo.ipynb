{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76620d4",
   "metadata": {},
   "source": [
    "# MindSpore Transformers Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001d65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops.operations as P\n",
    "import mindspore.ops.functional as F\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore import Parameter, Tensor\n",
    "from mindspore.common.initializer import initializer, HeUniform, Uniform, Normal, _calculate_fan_in_and_fan_out\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from layers import Dense, Embedding, Conv1d\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7ed925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, pad_mode='same', padding=0, dilation=1, group=1, has_bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, pad_mode, padding, dilation, group, has_bias, weight_init='normal', bias_init='zeros')\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.weight.set_data(initializer(HeUniform(math.sqrt(5)), self.weight.shape))\n",
    "        #self.weight = Parameter(initializer(HeUniform(math.sqrt(5)), self.weight.shape), name='weight')\n",
    "        if self.has_bias:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out(self.weight.shape)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            self.bias.set_data(initializer(Uniform(bound), [self.out_channels]))\n",
    "\n",
    "class Dense(nn.Dense):\n",
    "    def __init__(self, in_channels, out_channels, has_bias=True, activation=None):\n",
    "        super().__init__(in_channels, out_channels, weight_init='normal', bias_init='zeros', has_bias=has_bias, activation=activation)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.weight.set_data(initializer(HeUniform(math.sqrt(5)), self.weight.shape))\n",
    "        if self.has_bias:\n",
    "            fan_in, _ = _calculate_fan_in_and_fan_out(self.weight.shape)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            self.bias.set_data(initializer(Uniform(bound), [self.out_channels]))\n",
    "\n",
    "class Embedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embedding_size, use_one_hot=False, embedding_table='normal', dtype=ms.float32, padding_idx=None):\n",
    "        if embedding_table == 'normal':\n",
    "            embedding_table = Normal(1.0)\n",
    "        super().__init__(vocab_size, embedding_size, use_one_hot, embedding_table, dtype, padding_idx)\n",
    "    @classmethod\n",
    "    def from_pretrained_embedding(cls, embeddings:Tensor, freeze=True, padding_idx=None):\n",
    "        rows, cols = embeddings.shape\n",
    "        embedding = cls(rows, cols, embedding_table=embeddings, padding_idx=padding_idx)\n",
    "        embedding.embedding_table.requires_grad = not freeze\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1c742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(sentences, src_vocab, tgt_vocab):\n",
    "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
    "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
    "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
    "    return Tensor(input_batch, ms.int32), Tensor(output_batch, ms.int32), Tensor(target_batch, ms.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf00879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "    return Tensor(sinusoid_table, ms.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af9d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    \n",
    "    pad_attn_mask = P.Equal()(seq_k, 0)\n",
    "    pad_attn_mask = P.ExpandDims()(pad_attn_mask, 1) # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    pad_attn_mask = P.Cast()(pad_attn_mask, ms.float32)\n",
    "    return P.BroadcastTo((batch_size, len_q, len_k))(pad_attn_mask) # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fcb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequent_mask(subsequent_mask):\n",
    "    subsequent_mask = P.ExpandDims()(subsequent_mask, 0)\n",
    "    subsequent_mask = P.Cast()(subsequent_mask, ms.byte)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bf42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedFill(nn.Cell):\n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.value = Tensor([value], ms.float32)\n",
    "        self.minusend = Tensor([1.0], ms.float32)\n",
    "        self.sub = P.Sub()\n",
    "        self.mul = P.Mul()\n",
    "        \n",
    "    def construct(self, inputs:Tensor, mask:Tensor):\n",
    "        masked = self.sub(self.minusend, mask)\n",
    "        adder = self.mul(mask, self.value)\n",
    "        inputs = self.mul(masked, inputs)\n",
    "        output = inputs + adder\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8364420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Cell):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.scale = Tensor(d_k, ms.float32)\n",
    "        self.matmul = ops.matmul\n",
    "        self.transpose = P.Transpose()\n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "        self.sqrt = P.Sqrt()\n",
    "        self.masked_fill = MaskedFill(-1e9)\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        K = self.transpose(K, (0, 1, 3, 2))\n",
    "        scores = self.matmul(Q, K) / self.sqrt(self.scale) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores = self.masked_fill(scores, attn_mask) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = self.softmax(scores)\n",
    "        context = self.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ad20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.n_heads = n_heads\n",
    "        self.W_Q = Dense(d_model, d_k * n_heads)\n",
    "        self.W_K = Dense(d_model, d_k * n_heads)\n",
    "        self.W_V = Dense(d_model, d_k * n_heads)\n",
    "        self.linear = Dense(n_heads * d_k, d_model)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.attention = ScaledDotProductAttention(d_k)\n",
    "        # ops\n",
    "        self.transpose = P.Transpose()\n",
    "        self.expanddims = P.ExpandDims()\n",
    "        self.tile = P.Tile()\n",
    "        \n",
    "    def construct(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        q_s = self.W_Q(Q).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        k_s = self.W_K(K).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        v_s = self.W_V(V).view((batch_size, -1, self.n_heads, self.d_k)) \n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.transpose(q_s, (0, 2, 1, 3)) # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.transpose(k_s, (0, 2, 1, 3)) # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.transpose(v_s, (0, 2, 1, 3)) # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = self.expanddims(attn_mask, 1)\n",
    "        attn_mask = self.tile(attn_mask, (1, self.n_heads, 1, 1)) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "        \n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "        context = self.transpose(context, (0, 2, 1, 3)).view((batch_size, -1, self.n_heads * self.d_k)) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.linear(context) \n",
    "        return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c682bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_ff, d_model):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.transpose = P.Transpose()\n",
    "        \n",
    "    def construct(self, inputs):\n",
    "        residual = P.Cast()(inputs, ms.float32) # inputs : [batch_size, len_q, d_model]\n",
    "        output = self.transpose(inputs, (0, 2, 1))\n",
    "        output = self.conv1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.transpose(output, (0, 2, 1))\n",
    "        return self.layer_norm(output + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cfac0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58c43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, d_k, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778939e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, src_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, src_len):\n",
    "        super().__init__()\n",
    "        self.src_emb = Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(src_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([EncoderLayer(d_model, d_k, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        # temp positional indexes\n",
    "        self.pos = Tensor([[1, 2, 3, 4, 0]])\n",
    "        \n",
    "    def construct(self, enc_inputs):\n",
    "        # enc_inputs : [batch_size x source_len]\n",
    "        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(self.pos)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb78ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, tgt_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, tgt_len):\n",
    "        super().__init__()\n",
    "        self.tgt_emb = Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = Embedding.from_pretrained_embedding(get_sinusoid_encoding_table(tgt_len+1, d_model), freeze=True)\n",
    "        self.layers = nn.CellList([DecoderLayer(d_model, d_k, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        \n",
    "        # temp positional indexes\n",
    "        self.pos = Tensor([[5, 1, 2, 3, 4]])\n",
    "        \n",
    "        ones = np.ones(shape=(tgt_len, tgt_len))\n",
    "        self.subsequent_mask = Tensor(np.triu(ones, k=1), dtype=ms.float32)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        # dec_inputs : [batch_size x target_len]\n",
    "        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(self.pos)\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(self.subsequent_mask)\n",
    "        dec_self_attn_mask = P.Greater()((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "        \n",
    "        dec_self_attn_mask = P.Cast()(dec_self_attn_mask, ms.float32)\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n",
    "        \n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b73344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, src_len)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, d_k, n_heads, d_ff, n_layers, tgt_len)\n",
    "        self.projection = Dense(d_model, tgt_vocab_size, has_bias=False)\n",
    "    def construct(self, enc_inputs, dec_inputs):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
    "        return dec_logits.view((-1, dec_logits.shape[-1])), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c671a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "    def construct(self, *args):\n",
    "        outputs, _, _, _, = self._backbone(*args[:-1])\n",
    "        return self._loss_fn(outputs, args[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd7332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "# Transformer Parameters\n",
    "# Padding Should be Zero\n",
    "src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4}\n",
    "src_vocab_size = len(src_vocab)\n",
    "\n",
    "tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6}\n",
    "number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_len = 6 # length of source\n",
    "tgt_len = 5 # length of target\n",
    "\n",
    "d_model = 512  # Embedding Size\n",
    "d_ff = 2048  # FeedForward dimension\n",
    "d_k  = 64  # dimension of K(=Q), V\n",
    "n_layers = 6  # number of Encoder of Decoder Layer\n",
    "n_heads = 8  # number of heads in Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44157149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model, d_k, n_heads, d_ff, n_layers, src_vocab_size, tgt_vocab_size, src_len, tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef14d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.0001)\n",
    "# print(model.trainable_params())\n",
    "enc_inputs, dec_inputs, target_batch = make_batch(sentences, src_vocab, tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2a18d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.976681\n",
      "Epoch: 0002 cost = 1.485093\n",
      "Epoch: 0003 cost = 0.769337\n",
      "Epoch: 0004 cost = 0.629506\n",
      "Epoch: 0005 cost = 0.096533\n",
      "Epoch: 0006 cost = 0.014787\n",
      "Epoch: 0007 cost = 0.007234\n",
      "Epoch: 0008 cost = 0.006995\n",
      "Epoch: 0009 cost = 0.007764\n",
      "Epoch: 0010 cost = 0.007499\n",
      "Epoch: 0011 cost = 0.005996\n",
      "Epoch: 0012 cost = 0.004283\n",
      "Epoch: 0013 cost = 0.002976\n",
      "Epoch: 0014 cost = 0.002106\n",
      "Epoch: 0015 cost = 0.001537\n",
      "Epoch: 0016 cost = 0.001155\n",
      "Epoch: 0017 cost = 0.000892\n",
      "Epoch: 0018 cost = 0.000705\n",
      "Epoch: 0019 cost = 0.000571\n",
      "Epoch: 0020 cost = 0.000471\n"
     ]
    }
   ],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "net_with_criterion = WithLossCell(model, criterion)\n",
    "train_network = nn.TrainOneStepCell(net_with_criterion, optimizer)\n",
    "train_network.set_train()\n",
    "\n",
    "# Training\n",
    "for epoch in range(20):\n",
    "    # hidden : [num_layers * num_directions, batch, hidden_size]\n",
    "    loss = train_network(enc_inputs, dec_inputs, target_batch.view(-1))\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss.asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace7694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "predict, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "predict = predict.asnumpy().argmax(1)\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f752b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showgraph(attn):\n",
    "    attn = P.Squeeze(0)(attn[-1])[0]\n",
    "    attn = attn.asnumpy()\n",
    "    fig = plt.figure(figsize=(n_heads, n_heads)) # [n_heads, n_heads]\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attn, cmap='viridis')\n",
    "    ax.set_xticklabels(['']+sentences[0].split(), fontdict={'fontsize': 14}, rotation=90)\n",
    "    ax.set_yticklabels(['']+sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e23c1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first head of last state enc_self_attns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffding/anaconda3/envs/hwlab/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  import sys\n",
      "/home/jeffding/anaconda3/envs/hwlab/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first head of last state dec_self_attns\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first head of last state dec_enc_attns\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('first head of last state enc_self_attns')\n",
    "showgraph(enc_self_attns)\n",
    "\n",
    "print('first head of last state dec_self_attns')\n",
    "showgraph(dec_self_attns)\n",
    "\n",
    "print('first head of last state dec_enc_attns')\n",
    "showgraph(dec_enc_attns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
